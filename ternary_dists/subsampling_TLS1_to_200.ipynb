{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e03d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassiopeia as cas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from ete3 import Tree\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import randrange\n",
    "import itertools\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a079a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table of cell states\n",
    "cell_state_table = pd.read_csv('/Genomics/chanlab/blaw/TLS/metadata/TLS_120h_1_cellBC_cellState.tsv', sep='\\t')\n",
    "\n",
    "clusterColorsFile = \"/Genomics/chanlab/mchan/Adriano/TLS/TLS_TLSCL/20211102_clusterColorsTLSCL.p\"\n",
    "with open(clusterColorsFile,'rb') as fp:\n",
    "    colorDict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d840c4",
   "metadata": {},
   "source": [
    "# Subsample TLS1 to 200 cell allele tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8810e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "TLS1_allele_table = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-097/lineage/2_lineage_reconstruction/allele_table_filtered.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56d7bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# don't rerun this unless you want to create new downsampled allele tables\n",
    "for i in range(30):\n",
    "    temp_allele_cells = np.random.choice(TLS1_allele_table['cellBC'].unique(), size = 200, replace = False)\n",
    "    temp_allele = TLS1_allele_table[TLS1_allele_table['cellBC'].isin(temp_allele_cells)].copy()\n",
    "\n",
    "    if not os.path.exists('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/'.format('TLS1')):\n",
    "        os.mkdir('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/'.format('TLS1'))\n",
    "        os.mkdir('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/newick/'.format('TLS1'))\n",
    "        os.mkdir('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/allele_tables/'.format('TLS1'))\n",
    "        os.mkdir('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/trees/'.format('TLS1'))\n",
    "        os.mkdir('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/trees/logs/'.format('TLS1'))\n",
    "\n",
    "    temp_allele.to_csv('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/allele_tables/{}_{}_to_200_downsample_allele_table.txt'.format('TLS1', i, 'TLS1'), sep = '\\t')\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ec504",
   "metadata": {},
   "source": [
    "# Reconstruct these allele tables in the following python script\n",
    "\n",
    "- 'TLS1_to_200_downsampling_Lineage_Reconstruction.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bbc92",
   "metadata": {},
   "source": [
    "# Process the tree files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e6c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label internal nodes\n",
    "def nameInteriorNodes(nwkFile,outnwkFile):\n",
    "\n",
    "    t = Tree(nwkFile,format=1)\n",
    "    labelID = 0\n",
    "\n",
    "    for node in t.traverse():\n",
    "        if node.is_leaf() == False:\n",
    "            node.name = \"node{}\".format(labelID)\n",
    "            labelID = labelID + 1\n",
    "\n",
    "    t.write(format=8,outfile=outnwkFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec5d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node0(nwkFile, outnwkFile):\n",
    "    infile = open(nwkFile, 'r')\n",
    "    outfile = open(outnwkFile, 'w')\n",
    "    \n",
    "    outfile.write(infile.readline()[:-1])\n",
    "    outfile.write('node0;')\n",
    "          \n",
    "    infile.close()\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96882bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for barcode in ['TLS1']:\n",
    "    for i in range(30):\n",
    "        nameInteriorNodes('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/trees/{}_{}_to_200_downsampling_hybrid_newick_noMutationlessEdges.txt'.format(barcode, i, barcode),\n",
    "                          '/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/trees/{}_{}_to_200_downsampling_node0_missing.txt'.format(barcode, i, barcode))\n",
    "\n",
    "        add_node0('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/trees/{}_{}_to_200_downsampling_node0_missing.txt'.format(barcode, i, barcode),\n",
    "                  '/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/newick/{}_{}_to_200_downsampling_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, i, barcode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637040e5",
   "metadata": {},
   "source": [
    "# Make a node table that has all the replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f812141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxDepth(node):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "    returns:\n",
    "        - The max depth of any branch in that node\n",
    "    '''\n",
    "    if node.is_leaf():\n",
    "        return 0\n",
    "    children_depths = []\n",
    "    \n",
    "    for child in node.children:\n",
    "        test = maxDepth(child)\n",
    "        \n",
    "        children_depths.append(test)\n",
    "        \n",
    "    return max(children_depths) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ee8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNMP_Somite_Neural(node, cell_state_table):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "        - a table of cell states for each cellBC\n",
    "    return:\n",
    "        - A tuple of the number of NMP, somitic, and neural cells that are leaves of the node\n",
    "    '''\n",
    "    leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "\n",
    "    # Group the Neural and Somite cell states into 1 category and remove PGCLC, Endoderm, Unknown, Epithelial\n",
    "    somitic_count = 0\n",
    "    NMP_count = 0\n",
    "    neural_count = 0\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            somitic_count += 1\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            neural_count += 1\n",
    "        elif state in ['NMPs']:\n",
    "            NMP_count += 1\n",
    "\n",
    "    return (NMP_count, somitic_count, neural_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de95980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_columns = ['Sample_ID', 'Barcode', 'Node', 'Node Size', 'Clone', 'Clone Size', 'Max Clone Depth', 'Dist to Clone', 'Percent NMP', \n",
    "                'Percent Somitic', 'Percent Neural']\n",
    "\n",
    "node_info = pd.DataFrame(columns = node_columns)\n",
    "\n",
    "# Store the node information of nodes to filter\n",
    "bad_nodes = []\n",
    "small_nodes = []\n",
    "\n",
    "for barcode in ['TLS1']:\n",
    "    for i in range(30):\n",
    "        treeFile = '/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/newick/{}_{}_to_200_downsampling_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, i, barcode)\n",
    "        t = Tree(treeFile, format = 1)\n",
    "\n",
    "        # Add all nodes in the tree to the node_info dataframe\n",
    "        node_names = []\n",
    "        for node in t.traverse():\n",
    "            if node.name != 'node0' and not node.is_leaf():\n",
    "                node_names.append('{}_{}_{}'.format(i, barcode, node.name))\n",
    "\n",
    "        temp_node_info = pd.DataFrame(index = node_names, columns = node_columns)\n",
    "        node_info = pd.concat((node_info, temp_node_info))\n",
    "\n",
    "        # fill in node information, don't keep roots\n",
    "        for clone in t.children:\n",
    "            clone_max_depth = maxDepth(clone)\n",
    "\n",
    "            for node in clone.traverse():\n",
    "                if not node.is_leaf():\n",
    "                    leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "                    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "\n",
    "                    # Record nodes that need to be removed, currently removing any non NMP cell type and nodes with less than 4 leaves\n",
    "                    if 'Endoderm' in cell_types or 'PCGLC' in cell_types or 'Unknown' in cell_types or 'Endothelial' in cell_types:\n",
    "                        bad_nodes.append('{}_{}_{}'.format(i, barcode, node.name))\n",
    "                    elif len(leaves) < 4:\n",
    "                        small_nodes.append('{}_{}_{}'.format(i, barcode, node.name))\n",
    "\n",
    "                    NMP_count, somitic_count, neural_count = countNMP_Somite_Neural(node, cell_state_table)\n",
    "\n",
    "                    total = somitic_count + NMP_count + neural_count\n",
    "                    if total > 0:\n",
    "                        NMP_frac = NMP_count / total\n",
    "                        somitic_frac = somitic_count / total\n",
    "                        neural_frac = neural_count / total\n",
    "                    else:\n",
    "                        NMP_frac = 0\n",
    "                        somitic_frac = 0\n",
    "                        neural_frac = 0\n",
    "\n",
    "                    # Record node information to the large table\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Sample_ID'] = i\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Barcode'] = barcode\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Node'] = node.name\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Node Size'] = len(node.get_leaves())\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Clone'] = clone.name\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Clone Size'] = len(clone.get_leaves())\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Max Clone Depth'] = clone_max_depth\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Dist to Clone'] = t.get_distance(clone, node)\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Percent NMP'] = NMP_frac\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Percent Somitic'] = somitic_frac\n",
    "                    node_info.loc['{}_{}_{}'.format(i, barcode, node.name), 'Percent Neural'] = neural_frac\n",
    "\n",
    "node_info.drop(index = bad_nodes, inplace = True)\n",
    "node_info.drop(index = small_nodes, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc7a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the normalized Depth of each node\n",
    "node_info['Normalized Dist'] = node_info['Dist to Clone'] / node_info['Max Clone Depth']\n",
    "\n",
    "# Classify nodes by progenitor type and % extant NMPs\n",
    "node_info['Progenitor Type'] = '-'\n",
    "node_info['Progenitor Pool'] = '-'\n",
    "\n",
    "for node in node_info.index.values:\n",
    "    # A node is bipotent if it produces both neural and somitic cells\n",
    "    # Bipotent and transient bipotent (bipotent without NMPs) are both labeled as bipotent\n",
    "    if (node_info.loc[node, 'Percent Neural'] > 0) and (node_info.loc[node, 'Percent Somitic'] > 0):\n",
    "        node_info.loc[node, 'Progenitor Type'] = 'Bipotent'\n",
    "\n",
    "    # A node is committed towards the somitic lineage if it produces somites but not neural cells\n",
    "    elif (node_info.loc[node, 'Percent Somitic'] > 0) and (node_info.loc[node, 'Percent Neural'] == 0):\n",
    "        node_info.loc[node, 'Progenitor Type'] = 'Somitic Committed'\n",
    "\n",
    "    # A node is committed towards the neural lineage if it produces neural but not somitic cells\n",
    "    elif (node_info.loc[node, 'Percent Somitic'] == 0) and (node_info.loc[node, 'Percent Neural'] > 0):\n",
    "        node_info.loc[node, 'Progenitor Type'] = 'Neural Committed'\n",
    "\n",
    "    # A node is proliferating if it does not produce somitic or neural cells (exclusively produces NMPs)\n",
    "    elif (node_info.loc[node, 'Percent Somitic'] == 0) and (node_info.loc[node, 'Percent Neural'] == 0):\n",
    "        node_info.loc[node, 'Progenitor Type'] = 'Proliferating'\n",
    "\n",
    "\n",
    "    # A node is proliferating if it produces exclusively NMPs\n",
    "    if node_info.loc[node, 'Percent NMP'] == 1:\n",
    "        node_info.loc[node, 'Progenitor Pool'] = 'Proliferating'\n",
    "\n",
    "    # A node is differentiating if it produces some NMPS\n",
    "    elif node_info.loc[node, 'Percent NMP'] > 0:\n",
    "        node_info.loc[node, 'Progenitor Pool'] = 'Differentiating'\n",
    "\n",
    "    # A node is exhausted if it produces 0 NMPs\n",
    "    elif node_info.loc[node, 'Percent NMP'] == 0:\n",
    "        node_info.loc[node, 'Progenitor Pool'] = 'Exhausted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e7d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info.to_csv('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/TLS1_to_200_node_information_filtered.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2c791",
   "metadata": {},
   "source": [
    "# Calculate the distance between all the pairwise trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a275a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDist(node1, node2, node_info):\n",
    "    '''\n",
    "    input:\n",
    "        node1 - a name of the first node, assumed to be an index in node_info\n",
    "        node2 - a name of the second node, assumed to be an index in node_info\n",
    "        node_info - a node info table that has the fraction of NMP, Neural, and Somitic columns\n",
    "        \n",
    "    returns:\n",
    "        The euclidean distance between the 2 nodes from the 3 fractions\n",
    "    '''\n",
    "    x1 = node_info.loc[node1, 'Percent NMP']\n",
    "    y1 = node_info.loc[node1, 'Percent Neural']\n",
    "    z1 = node_info.loc[node1, 'Percent Somitic']\n",
    "    \n",
    "    x2 = node_info.loc[node2, 'Percent NMP']\n",
    "    y2 = node_info.loc[node2, 'Percent Neural']\n",
    "    z2 = node_info.loc[node2, 'Percent Somitic']\n",
    "    \n",
    "    return np.sqrt((x1-x2)**2 + (y1-y2)**2 + (z1-z2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3621637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTernaryDist(tree1_name, tree2_name, node_info, meta_col = 'Sample_ID'):\n",
    "    '''\n",
    "    input:\n",
    "        tree1 - string to subset all nodes in tree1 using the meta_col, assumed to all be in the node_info table\n",
    "        tree2 - string to subset all nodes in tree1 using the meta_col, assumed to all be in the node_info table\n",
    "        node_info - a node_info table that contains all nodes in tree1 and tree2, the column from meta_col and the fractions of NMP, Neural, and Somitic.\n",
    "        meta_col - A column name in node_info that can be used to split tree1 and tree2\n",
    "    returns:\n",
    "        a value of the distance between tree1 and tree2\n",
    "    '''\n",
    "    tree1_nodes = node_info[node_info[meta_col] == tree1_name].index\n",
    "    tree2_nodes = node_info[node_info[meta_col] == tree2_name].index\n",
    "    \n",
    "    pairwise_dists_df = pd.DataFrame(index = tree1_nodes, columns = tree2_nodes)\n",
    "    \n",
    "    for i in pairwise_dists_df.index:\n",
    "        for j in pairwise_dists_df.columns:\n",
    "            pairwise_dists_df.loc[i, j] = calcDist(i, j, node_info)\n",
    "            \n",
    "    total_dist = 0\n",
    "    pen = 0 \n",
    "    temp_dists_df = pairwise_dists_df.copy()\n",
    "    min_nodes = min(len(temp_dists_df.columns), len(temp_dists_df.index))\n",
    "    for i in range(max(len(temp_dists_df.columns), len(temp_dists_df.index))):\n",
    "        if len(temp_dists_df.columns) == 0 or len(temp_dists_df.index) == 0:\n",
    "            pen += 1\n",
    "        else:\n",
    "            min_val = 100\n",
    "            min_col = '' \n",
    "            min_row = ''\n",
    "            for col in temp_dists_df.columns:\n",
    "                temp_dists_df[col] = pd.to_numeric(temp_dists_df[col])\n",
    "\n",
    "                temp_row = temp_dists_df[col].idxmin(axis = 0)\n",
    "                if min_val > temp_dists_df.loc[temp_row, col]:\n",
    "                    min_val = temp_dists_df.loc[temp_row, col]\n",
    "                    min_row = temp_row\n",
    "                    min_col = col\n",
    "\n",
    "            total_dist += temp_dists_df.loc[min_row, min_col]\n",
    "\n",
    "            temp_dists_df.drop(index = min_row, inplace = True)\n",
    "            temp_dists_df.drop(columns = min_col, inplace = True)    \n",
    "            \n",
    "    return (total_dist / min_nodes, (total_dist / min_nodes) + pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f3f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_trees = list(itertools.combinations(node_info['Sample_ID'].unique(), 2))\n",
    "comparison_list = []\n",
    "\n",
    "for x, y in pairwise_trees:\n",
    "    comparison_list.append('{}_{}'.format(x, y))\n",
    "\n",
    "TLS1_dists_df = pd.DataFrame(index = comparison_list, columns = ['ID_1', 'ID_2', 'Dist', 'Pen_Dist', 'Comp_Dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725ea861",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ID_1, ID_2 in pairwise_trees:\n",
    "    name = '{}_{}'.format(ID_1, ID_2)\n",
    "    dist, pen_dist = calcTernaryDist(int(ID_1), int(ID_2), node_info)\n",
    "\n",
    "    TLS1_dists_df.loc[name] = [ID_1, ID_2, dist, pen_dist, '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c3240",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1727a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(TLS1_dists_df['Dist'], labels = ['Intra TLS1'])\n",
    "plt.ylim(0, 0.8)\n",
    "plt.ylabel('Normalized Ternary Dist')\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/results/TLS1_ternary_dist.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17700903",
   "metadata": {},
   "source": [
    "# Find composition distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92b4d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aitchisonDist (x, y):\n",
    "    '''\n",
    "    Input:\n",
    "        x - a list or array of composition values in sample1\n",
    "        y - a list or array of composition values in sample2\n",
    "        \n",
    "        Assumes that all 0 values have been removed and that the composition values in the list are connected by index\n",
    "    return:\n",
    "        a distance between the 2 vectors\n",
    "    '''\n",
    "    meanX = sum(x) / len(x)\n",
    "    meanY = sum(y) / len(y)\n",
    "    \n",
    "    distSum = 0\n",
    "    \n",
    "    for index, value in enumerate(x):\n",
    "        tempX = np.log(x[index] / meanX)\n",
    "        tempY = np.log(y[index] / meanY)\n",
    "        \n",
    "        distSum += (tempX - tempY) ** 2\n",
    "        \n",
    "    return np.sqrt(distSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c57f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TLS_compositions = pd.DataFrame(index = node_info['Sample_ID'].unique(), columns = colorDict.keys())\n",
    "\n",
    "temp_cell_state_table = cell_state_table.copy()\n",
    "temp_cell_state_table.set_index('cellBC', inplace = True)\n",
    "\n",
    "for index in TLS_compositions.index:\n",
    "    ID = index\n",
    "    barcode = 'TLS1'\n",
    "    \n",
    "    cell_counts = {}\n",
    "    \n",
    "    for i in colorDict.keys():\n",
    "        cell_counts[i] = 0\n",
    "    \n",
    "    treeFile = '/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/{}_to_200/newick/{}_{}_to_200_downsampling_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, ID, barcode)\n",
    "\n",
    "    t = Tree(treeFile, format = 1)\n",
    "    leaves = [leaf.name for leaf in t.get_leaves()]\n",
    "    #print(len(leaves))\n",
    "    \n",
    "    for leaf in leaves:\n",
    "        cell_counts[temp_cell_state_table.loc[leaf, 'cell_state']] += 1\n",
    "        \n",
    "    for cell_state in cell_counts.keys():\n",
    "        TLS_compositions.loc[index, cell_state] = cell_counts[cell_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4199939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress all the cell types down to just 3 categories\n",
    "temp_TLS_compositions = pd.DataFrame(index = TLS_compositions.index, columns = ['NMPs', 'Neural', 'Somitic'])\n",
    "\n",
    "for i in temp_TLS_compositions.index:\n",
    "    temp_TLS_compositions.loc[i, 'NMPs'] = TLS_compositions.loc[i, 'NMPs']\n",
    "    \n",
    "    temp_TLS_compositions.loc[i, 'Neural'] = TLS_compositions.loc[i, ['NeuralTube1', 'NeuralTube2']].sum()\n",
    "    temp_TLS_compositions.loc[i, 'Somitic'] = TLS_compositions.loc[i, ['pPSM', 'aPSM', 'Somite-1', 'Somite0', 'Somite', 'SomiteSclero', 'SomiteDermo']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b8ed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in TLS1_dists_df.index:\n",
    "    ID_1 = int(TLS1_dists_df.loc[i, 'ID_1'])\n",
    "    ID_2 = int(TLS1_dists_df.loc[i, 'ID_2'])\n",
    "    \n",
    "    x_vector = temp_TLS_compositions.loc[ID_1].values + 0.0001\n",
    "    y_vector = temp_TLS_compositions.loc[ID_2].values + 0.0001\n",
    "    \n",
    "    TLS1_dists_df.loc[i, 'Comp_Dist'] = aitchisonDist(x_vector, y_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43f3efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TLS1_dists_df.to_csv('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/TLS1_to_200/TLS1_to_200_intra_structure_dists.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6859a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "TLS1_dists_df = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/TLS1_to_200/TLS1_to_200_intra_structure_dists.txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [TLS1_dists_df['Comp_Dist']]\n",
    "\n",
    "plt.boxplot(data, labels = ['TLS1'])\n",
    "plt.title('Intra Compositional Distances')\n",
    "plt.ylabel('Aitchison Distance')\n",
    "plt.ylim(0, 2)\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/results/TLS1_composition_dist.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45abba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept, color):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--{}'.format(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f189bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5, 5))\n",
    "\n",
    "labels = []\n",
    "\n",
    "plt.plot(TLS1_dists_df['Comp_Dist'], TLS1_dists_df['Dist'], '.r', alpha = 0.05)\n",
    "slope_temp, intercept_temp, r, p, se = stats.linregress(TLS1_dists_df['Comp_Dist'].tolist(), TLS1_dists_df['Dist'].tolist())\n",
    "abline(slope_temp, intercept_temp, 'r')\n",
    "\n",
    "plt.legend(labels = ['TLS1 Intra', 'TLS1 Intra Line'], bbox_to_anchor=(1, 0.55))\n",
    "plt.title('Ternary Dist vs Compositional Dist')\n",
    "plt.xlabel('Comp Dist')\n",
    "plt.ylabel('Ternary Dist')\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/ternary_dists/downsampling_to_200/TLS1_to_200/TLS1_ternary_vs_comp_dist.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

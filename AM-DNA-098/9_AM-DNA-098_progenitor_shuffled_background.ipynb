{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5447d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import cassiopeia as cas\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "from matplotlib.pyplot import rc_context\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from ete3 import Tree\n",
    "from typing import Tuple\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c3daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterColorsFile = \"/Genomics/chanlab/mchan/Adriano/TLS/TLS_TLSCL/20211102_clusterColorsTLSCL.p\"\n",
    "with open(clusterColorsFile,'rb') as fp:\n",
    "    colorDict = pickle.load(fp)\n",
    "\n",
    "# Load the allele table, tree, and lineage table for TLS1\n",
    "TLS2_allele_table = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/lineage/2_lineage_reconstruction/allele_table.txt', sep='\\t')\n",
    "\n",
    "# Load the TLS1 tree\n",
    "TLS2_loc = '/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/lineage/2_lineage_reconstruction/AM-DNA-098_hybrid_newick_noMutationlessEdges_Labeled.nwk'\n",
    "t = Tree(TLS2_loc, format=1)\n",
    "\n",
    "# Load the cell state table\n",
    "cell_state_table = pd.read_csv('/Genomics/chanlab/blaw/TLS/LineageTracer/scRNAseq/TLS_120h_2_cellBC_cellState.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fddaaa",
   "metadata": {},
   "source": [
    "# Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a81770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxDepth(node):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "    returns:\n",
    "        - The max depth of any branch in that node\n",
    "    '''\n",
    "    if node.is_leaf():\n",
    "        return 0\n",
    "    children_depths = []\n",
    "    \n",
    "    for child in node.children:\n",
    "        test = maxDepth(child)\n",
    "        \n",
    "        children_depths.append(test)\n",
    "        \n",
    "    return max(children_depths) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70921cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProgenitorType(leaves, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a list of leaves that are extant cells for a node\n",
    "        - a table that contains the annotated cell state for each cellBC\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    - Extended progenitors: PGCs, Endoderm, Somitic, Neural\n",
    "    - Pluripotent progenitors: Endoderm, Somitic, Neural\n",
    "    - Bipotent progenitors: Somitic, Neural (both if contains or not NMPs still count)\n",
    "    - Endoderm progenitors: Endoderm only\n",
    "    - PGCLC progenitors: PGCLC only\n",
    "    - Somitic progenitors: somitic only\n",
    "    - Neural progenitors: neural only\n",
    "    \n",
    "    Neural class is made from NeuralTube1 and NeuralTube2\n",
    "    Somite class is pPSM, aPSM, Somite-1, Somite0, Somite, Somite1, SomiteSclero, SomiteDermo\n",
    "    \n",
    "    NMPs are left out of the analysis. +/- an NMP does not change the category that a node gets\n",
    "    \n",
    "    exclude nodes that are Endoderm without both somitic and neural (unless it is alone)\n",
    "    exclude nodes that are PGC without all 3 endoderm, somitic, and neural (unless it is alone)\n",
    "    \n",
    "    Endothelial is allowed (+/-) in extended progenitors and pluripotent progenitors\n",
    "    Endothelial is not allowed (-) in all other progenitors\n",
    "    \n",
    "    Unassigned / Unknown cells are not looked at for this classification (+/-)\n",
    "    \n",
    "    I am changing this analysis to also record if a node is exclusively NMP (self renewing NMP)\n",
    "    \n",
    "    '''\n",
    "    progenitor_types = {'Extended Progenitor': set(['PCGLC', 'Endoderm', 'Somitic', 'Neural']),\n",
    "                        'Pluripotent Progenitor': set(['Endoderm', 'Somitic', 'Neural']),\n",
    "                        'Bipotent Progenitor' : set(['Somitic', 'Neural']),\n",
    "                        'Endoderm Progenitor': set(['Endoderm']),\n",
    "                        'PGCLC Progenitor': set(['PCGLC']),\n",
    "                        'Somitic Progenitor': set(['Somitic']),\n",
    "                        'Neural Progenitor': set(['Neural'])}\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "    \n",
    "    #if set(cell_types) == set(['NMPs']):\n",
    "     #   return 'Self Renewing NMP'\n",
    "    \n",
    "    # Group the cell states into neural and somite categories\n",
    "    grouped_states = []\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            grouped_states.append('Somitic')\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            grouped_states.append('Neural')\n",
    "        elif state in ['PCGLC', 'Endoderm', 'Endothelial']:\n",
    "            grouped_states.append(state)\n",
    "    \n",
    "    state_set = set(grouped_states)\n",
    "    \n",
    "    for progenitor in progenitor_types.keys():\n",
    "        if state_set == progenitor_types[progenitor]:\n",
    "            return progenitor\n",
    "    if state_set == set(['PCGLC', 'Endoderm', 'Somitic', 'Neural', 'Endothelial']):\n",
    "        return 'Extended Progenitor'\n",
    "    if state_set == set(['Endoderm', 'Somitic', 'Neural', 'Endothelial']):\n",
    "        return 'Pluripotent Progenitor'\n",
    "    \n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd9c2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProgenitorType_FC(leaves, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a tree node to test\n",
    "        - a table that contains the annotated cell state for each cellBC\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    Record the cell states that are connected to a node from the following 6 states:\n",
    "    - PGCLC\n",
    "    - Endoderm\n",
    "    - Endothelial\n",
    "    - NMPs\n",
    "    - Somitic\n",
    "    - Neural\n",
    "    \n",
    "    Neural class is made from NeuralTube1 and NeuralTube2\n",
    "    Somite class is pPSM, aPSM, Somite-1, Somite0, Somite, Somite1, SomiteSclero, SomiteDermo\n",
    "    \n",
    "    Unassigned / Unknown cells are not looked at for this classification (+/-)\n",
    "    \n",
    "    '''\n",
    "    states = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "    total_combinations = []\n",
    "    for i in range(5):\n",
    "        for j in itertools.combinations(states, i+2):\n",
    "            total_combinations.append(j)\n",
    "\n",
    "    progenitor_type_dict = {'PCGLC': set(['PCGLC']),\n",
    "                       'Endoderm': set(['Endoderm']),\n",
    "                       'Endothelial': set(['Endothelial']),\n",
    "                       'NMPs': set(['NMPs']),\n",
    "                       'Somitic': set(['Somitic']),\n",
    "                       'Neural': set(['Neural'])}\n",
    "    for i in total_combinations:\n",
    "        label = '_'.join(i)\n",
    "        progenitor_type_dict[label] = set(i)\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "    \n",
    "    # Group the cell states into neural and somite categories\n",
    "    grouped_states = []\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            grouped_states.append('Somitic')\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            grouped_states.append('Neural')\n",
    "        elif state in ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs']:\n",
    "            grouped_states.append(state)\n",
    "    \n",
    "    state_set = set(grouped_states)\n",
    "    \n",
    "    for progenitor in progenitor_type_dict.keys():\n",
    "        if state_set == progenitor_type_dict[progenitor]:\n",
    "            return progenitor\n",
    "    \n",
    "    # Return dropped if a node is not in the progenitor type dict\n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0fa3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffledBG (file_name, empty_node_info, cell_state_table, node_leaf_dict, dropped_leaf_dict, output_dir, FC = False, numShuffles = 500):\n",
    "    '''\n",
    "    input:\n",
    "        file_name - an experiment name for saving the files\n",
    "        empty_node_info - a table that contains all the nodes in the tree as indexes and a 'Progenitor Type' column to be populated\n",
    "        cell_state_table - a table that contains the assigned cell state for each cell in the tree. Any nodes that are added \n",
    "            back after the trimming (keeping the top node of a nest set) should be added into these columns. This table should\n",
    "            ONLY contain cells that are present on the tree / node table so that the shuffling is accurate\n",
    "        node_leaf_dict - a dictionary that saves a list of leaves that are extant cells for a given node (key)\n",
    "        dropped_leaf_dict - a dictionary that saves the cells that are removed from the tree (via trimming) as keys and the \n",
    "            new node values as values to be looked up in the cell state table\n",
    "        output_dir - a file path to a directory to save the files and graphs\n",
    "        FC - a boolean to use the full combination of progenitor states or the smaller subset (default to False)\n",
    "        shuffles - the number of iterations to do the shuffled BG (default to 500)\n",
    "    output:\n",
    "        df_bgCounts - a dataframe of the counts for each progenitor state in each iteration of the shuffledBG \n",
    "            (saved as a csv file to output_dir)\n",
    "        df_bgVals - a dataframe of the mean and median of normalized depth for each progenitor state for each itr\n",
    "            (saved as a csv file to output_dir)\n",
    "        bgDist_dict - a dictionary that saves a list of arrays of normalized depth for each progenitor state for each itr\n",
    "            (saved as a pickle .p file to output_dir)\n",
    "    '''\n",
    "    # check if the output_dir is real\n",
    "    if not os.path.exists(output_dir):\n",
    "        print('output_dir path does not exists')\n",
    "        return\n",
    "    \n",
    "    # shuffle background and calculate the # of each progenitor type for the entire dataset\n",
    "    itrList = ['itr' + str(i) for i in range(numShuffles)]\n",
    "    \n",
    "    # set a dictionary of the progenitor types based on the full set of progenitor types or the reduced set\n",
    "    if FC:\n",
    "        states = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "        progenitor_types = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "        for i in range(5):\n",
    "            for j in itertools.combinations(states, i+2):\n",
    "                progenitor_types.append('_'.join(j))\n",
    "    else:\n",
    "        progenitor_types = ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', 'PGCLC Progenitor', 'Endoderm Progenitor', 'Dropped']\n",
    "    \n",
    "\n",
    "    indexList = []\n",
    "    for progenitor in progenitor_types:\n",
    "        for i in ['Mean', 'Median']:\n",
    "            indexList.append(progenitor + '_' + i)\n",
    "    \n",
    "    # initialize the 3 variables to save the results\n",
    "    df_bgCounts = pd.DataFrame(index = progenitor_types, columns = itrList)\n",
    "    df_bgVals = pd.DataFrame(index = indexList, columns = itrList)\n",
    "    bgDists_dict = {}\n",
    "\n",
    "    for itr in range(numShuffles):\n",
    "        # Assign a temp node_info table with progenitor types not classified\n",
    "        node_info_itr = empty_node_info.copy()\n",
    "\n",
    "        # Randomly shuffle the cell_state annotations in a cell state table\n",
    "        shuffled_cell_state_table = cell_state_table.copy()\n",
    "        shuffled_cell_state_table['cell_state'] = shuffled_cell_state_table['cell_state'].sample(frac = 1).values\n",
    "\n",
    "        # fill the node_info_itr table with node classifications using the shuffled cell state table\n",
    "        for node in node_info_itr.index:\n",
    "            leaves = []\n",
    "            for leaf in node_leaf_dict[node]:\n",
    "                if leaf in dropped_leaf_dict.keys():\n",
    "                    leaves.append(dropped_leaf_dict[leaf])\n",
    "                else:\n",
    "                    leaves.append(leaf)\n",
    "            if FC:\n",
    "                node_info_itr.loc[node]['Progenitor Type'] = getProgenitorType_FC(leaves, shuffled_cell_state_table)\n",
    "            else:\n",
    "                node_info_itr.loc[node]['Progenitor Type'] = getProgenitorType(leaves, shuffled_cell_state_table)\n",
    "\n",
    "        for progenitor in progenitor_types:\n",
    "            df_bgCounts.loc[progenitor, 'itr{}'.format(itr)] = len(node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Clone'])  \n",
    "\n",
    "        for progenitor in progenitor_types:\n",
    "            # assign the mean and median to be 0 if the node type was not observed in this iteration\n",
    "            if df_bgCounts.loc[progenitor, 'itr{}'.format(itr)] > 0:\n",
    "                df_bgVals.loc[progenitor + '_Mean', 'itr{}'.format(itr)] = node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Normalized Dist'].mean()\n",
    "                df_bgVals.loc[progenitor + '_Median', 'itr{}'.format(itr)] = node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Normalized Dist'].median()\n",
    "            else:\n",
    "                df_bgVals.loc[progenitor + '_Mean', 'itr{}'.format(itr)] = 0\n",
    "                df_bgVals.loc[progenitor + '_Median', 'itr{}'.format(itr)] = 0\n",
    "\n",
    "        for progenitor in progenitor_types:\n",
    "            # check if this progenitor has not been added to the dict yet\n",
    "            if progenitor not in bgDists_dict.keys():\n",
    "                bgDists_dict[progenitor] = []\n",
    "\n",
    "            # If the progenitor is observed in this iteration, then add the array of normalized depths to the list\n",
    "            if df_bgCounts.loc[progenitor, 'itr{}'.format(itr)] > 0:\n",
    "                bgDists_dict[progenitor].append(node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Normalized Dist'])\n",
    "\n",
    "                \n",
    "    # Save the 3 objects\n",
    "    with open(output_dir + '{}_shuffledBG_Distributions.pickle'.format(file_name), 'wb') as handle:\n",
    "        pickle.dump(bgDists_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    df_bgVals.to_csv(output_dir + '{}_shuffledBG_Means.txt'.format(file_name))\n",
    "\n",
    "    df_bgCounts.to_csv(output_dir + '{}_shuffledBG_Counts.txt'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9de81",
   "metadata": {},
   "source": [
    "# Make an empty node info table\n",
    "- This table will have the clone information, max clone depth, and normalized dist from clone for each node\n",
    "- Progenitor type will be added during the shuffledBG function for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e4c2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the nodes in TLS2\n",
    "# Do not include the root since we know that this structure starts from multiple cells\n",
    "nodes = []\n",
    "for node in t.traverse():\n",
    "    if not node.is_leaf():\n",
    "        if node.name != 'node0':\n",
    "            nodes.append(node.name)\n",
    "            \n",
    "empty_node_info = pd.DataFrame(index = nodes, columns = ['Clone', 'Dist to Clone', 'Clone Depth', 'Progenitor Type', 'Normalized Dist'])\n",
    "\n",
    "# Fill in topology information\n",
    "for clone in t.children:\n",
    "    clone_depth = maxDepth(clone)\n",
    "    \n",
    "    for node in clone.traverse():\n",
    "        if not node.is_leaf():\n",
    "            dist_to_clone = t.get_distance(clone, node)\n",
    "            \n",
    "            empty_node_info.loc[node.name, 'Clone'] = clone.name\n",
    "            empty_node_info.loc[node.name, 'Dist to Clone'] = dist_to_clone\n",
    "            empty_node_info.loc[node.name, 'Clone Depth'] = clone_depth\n",
    "            if clone_depth == 1:\n",
    "                empty_node_info.loc[node.name, 'Normalized Dist'] = 0\n",
    "            else:\n",
    "                empty_node_info.loc[node.name, 'Normalized Dist'] = dist_to_clone / (clone_depth - 1)\n",
    "        \n",
    "# filter the cell state table to only the cells in the tree\n",
    "leaves = [leaf.name for leaf in t.get_leaves()]\n",
    "tree_cell_state_table = cell_state_table[cell_state_table['cellBC'].isin(leaves)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247091e",
   "metadata": {},
   "source": [
    "# Label Progenitor Nodes in the Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d3d2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label clones\n",
    "for clone in t.children:\n",
    "    if not clone.is_leaf():\n",
    "        empty_node_info.loc[clone.name, 'Progenitor Type'] = 'Clone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cd4cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary that stores the subnodes (not including leaves) for each node in the tree\n",
    "node_subnode_dict = {}\n",
    "# Make a dictionary that stores the leaves for each node in the tree\n",
    "node_leaf_dict = {}\n",
    "\n",
    "# Iter through all the nodes in t and populate two dictionaries for non-leaf nodes\n",
    "for node in t.traverse():\n",
    "    if not node.is_leaf():\n",
    "        node_leaf_dict[node.name] = [leaf.name for leaf in node.get_leaves()]\n",
    "        \n",
    "        children = []\n",
    "        \n",
    "        for subnode in node.traverse():\n",
    "            if not subnode.is_leaf() and subnode != node:\n",
    "                children.append(subnode.name)\n",
    "            \n",
    "        node_subnode_dict[node.name] = children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ade9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info = empty_node_info.copy()\n",
    "\n",
    "# For each node that is not a clone, record the progenitor type\n",
    "for clone in t.children:\n",
    "    for node in clone.traverse():\n",
    "        if not node.is_leaf():\n",
    "            leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "            node_info.loc[node.name, 'Progenitor Type'] = getProgenitorType(leaves, cell_state_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77be7925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Progenitor\n",
      "27\n",
      "Pluripotent Progenitor\n",
      "64\n",
      "Bipotent Progenitor\n",
      "187\n",
      "Neural Progenitor\n",
      "82\n",
      "Somitic Progenitor\n",
      "353\n",
      "PGCLC Progenitor\n",
      "32\n",
      "Endoderm Progenitor\n",
      "10\n",
      "Dropped\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "progenitor_types = ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', 'PGCLC Progenitor', 'Endoderm Progenitor', 'Dropped']\n",
    "\n",
    "for progenitor in progenitor_types:\n",
    "    print(progenitor)\n",
    "    print(len(node_info[node_info['Progenitor Type'] == progenitor]['Clone Depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5daaf",
   "metadata": {},
   "source": [
    "# Shuffled Background for Progenitor Type Counts\n",
    "For every shuffled background in ~500 repeats:\n",
    "- shuffle the cell states around the tree\n",
    "- classify the nodes\n",
    "- count the progenitor types\n",
    "- record the progenitor types\n",
    "\n",
    "This can be done by shuffling the cell state annotations that are drawn from the cell_state_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d69aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledBG(file_name = 'AM-DNA-098',\n",
    "           empty_node_info = empty_node_info,\n",
    "           cell_state_table = tree_cell_state_table,\n",
    "           node_leaf_dict = node_leaf_dict,\n",
    "           dropped_leaf_dict = {},\n",
    "           output_dir = '/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/',\n",
    "           FC = False,\n",
    "           numShuffles = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1c1cc",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8300db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "\n",
    "# Start a figure for the cdf plots for each progneitor type in the untrimmed not full combination dataset\n",
    "fig, ax = plt.subplots(2, 4, figsize = (16, 8))\n",
    "axes = [ax[0, 0], ax[0, 1], ax[0, 2], ax[0, 3], ax[1, 0], ax[1, 1], ax[1, 2], ax[1, 3]]\n",
    "\n",
    "count = 0\n",
    "for progenitor in bgDists_dict.keys():\n",
    "    temp_ax = axes[count]\n",
    "    count += 1\n",
    "    \n",
    "    for i in bgDists_dict[progenitor]:\n",
    "        sns.ecdfplot(i, ax=temp_ax, color = 'lightblue', alpha = 0.1)\n",
    "\n",
    "# Plot the actual data\n",
    "count = 0\n",
    "for progenitor in bgDists_dict.keys():\n",
    "    temp_ax = axes[count]\n",
    "    count += 1\n",
    "    \n",
    "    sns.ecdfplot(node_info[node_info['Progenitor Type'] == progenitor]['Normalized Dist'], ax = temp_ax, color = 'Black')\n",
    "    temp_ax.set_title(progenitor)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_node_depths.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661ab78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n"
     ]
    }
   ],
   "source": [
    "# Plot violin plots of the mean counts with a dot for the actual value\n",
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_shuffledBG_Counts.txt', index_col = 0)\n",
    "\n",
    "# Get the actual values from the above node table\n",
    "actual_values =[]\n",
    "for progenitor in progenitor_types:\n",
    "    actual_values.append(len(node_info[node_info['Progenitor Type'] == progenitor]['Clone']))\n",
    "    \n",
    "fig, ax = plt.subplots(figsize = (20, 5))\n",
    "sns.violinplot(data = df_bgCounts.T, scale = 'width')\n",
    "sns.swarmplot(x = progenitor_types, y = actual_values, color = 'Blue')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_Progenitor_Counts.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa8584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'Extended Progenitor': 'black', 'Pluripotent Progenitor': 'Orange', 'Bipotent Progenitor': 'Blue',\n",
    "         'Neural Progenitor': 'Green', 'Somitic Progenitor': 'Red'}\n",
    "\n",
    "# Start a figure for the cdf plots for each progneitor type in the untrimmed not full combination dataset\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 4))\n",
    "\n",
    "# Plot the actual data\n",
    "count = 0\n",
    "for progenitor in ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor']:    \n",
    "    sns.ecdfplot(node_info[node_info['Progenitor Type'] == progenitor]['Normalized Dist'], color = colors[progenitor])\n",
    "\n",
    "ax.legend(['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor'])\n",
    "plt.title('TLS2')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_node_depths_combined.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e007f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_shuffledBG_Counts.txt', index_col = 0)\n",
    "df_bgVals = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_shuffledBG_Means.txt', index_col = 0)\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "\n",
    "# Make a table of actual count, mean BG count, std BG count, zscore, pval, actual dist mean, BG dist mean, BG dist std, zscore, pval\n",
    "values = ['Actual_Count', 'Mean_BG_Count', 'Std_BG_Count', 'zscore_Count', 'pval_L_Count', 'pval_U_Count', 'Actual_Dist', 'Mean_BG_Dist', 'Std_BG_Dist', 'zscore_Dist', 'pval_L_Dist', 'pval_U_Dist']\n",
    "\n",
    "progenitor_stats = pd.DataFrame(index = bgDists_dict.keys(), columns = values)\n",
    "\n",
    "for progenitor in progenitor_stats.index:\n",
    "    actualCount = len(node_info[node_info['Progenitor Type'] == progenitor]['Clone Depth'])\n",
    "    meanCount = df_bgCounts.loc[progenitor].mean()\n",
    "    stdCount = df_bgCounts.loc[progenitor].std()\n",
    "    zScore = (actualCount - meanCount) / stdCount\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above = []\n",
    "    below = []\n",
    "    equal = []\n",
    "    for i in df_bgCounts.loc[progenitor]:\n",
    "        if i > actualCount:\n",
    "            above.append(i)\n",
    "        elif i < actualCount:\n",
    "            below.append(i)\n",
    "        else:\n",
    "            equal.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower = (len(below) + len(equal)) / 500\n",
    "    pval_upper = (len(above) + len(equal)) / 500\n",
    "    \n",
    "    progenitor_stats.loc[progenitor, 'Actual_Count'] = actualCount\n",
    "    progenitor_stats.loc[progenitor, 'Mean_BG_Count'] = meanCount\n",
    "    progenitor_stats.loc[progenitor, 'Std_BG_Count'] = stdCount\n",
    "    progenitor_stats.loc[progenitor, 'zscore_Count'] = zScore\n",
    "    progenitor_stats.loc[progenitor, 'pval_L_Count'] = pval_lower\n",
    "    progenitor_stats.loc[progenitor, 'pval_U_Count'] = pval_upper\n",
    "    \n",
    "    # Record all the info for the normalized distributions\n",
    "    actualDist = node_info[node_info['Progenitor Type'] == progenitor]['Normalized Dist'].mean()\n",
    "    meanDist = df_bgVals.loc[progenitor + '_Mean'].mean()\n",
    "    stdDist = df_bgVals.loc[progenitor + '_Mean'].std()\n",
    "    zScoreDist = (actualDist - meanDist) / stdDist\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above_Dist = []\n",
    "    below_Dist = []\n",
    "    equal_Dist = []\n",
    "    for i in df_bgVals.loc[progenitor + '_Mean']:\n",
    "        if i > actualDist:\n",
    "            above_Dist.append(i)\n",
    "        elif i < actualDist:\n",
    "            below_Dist.append(i)\n",
    "        else:\n",
    "            equal_Dist.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower_Dist = (len(below_Dist) + len(equal_Dist)) / 500\n",
    "    pval_upper_Dist = (len(above_Dist) + len(equal_Dist)) / 500\n",
    "    \n",
    "    progenitor_stats.loc[progenitor, 'Actual_Dist'] = actualDist\n",
    "    progenitor_stats.loc[progenitor, 'Mean_BG_Dist'] = meanDist\n",
    "    progenitor_stats.loc[progenitor, 'Std_BG_Dist'] = stdDist\n",
    "    progenitor_stats.loc[progenitor, 'zscore_Dist'] = zScoreDist\n",
    "    progenitor_stats.loc[progenitor, 'pval_L_Dist'] = pval_lower_Dist\n",
    "    progenitor_stats.loc[progenitor, 'pval_U_Dist'] = pval_upper_Dist\n",
    "    \n",
    "progenitor_stats.to_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_small_set/AM-DNA-098_Progenitor_Stats.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2c4ca",
   "metadata": {},
   "source": [
    "# ShuffledBG using the full set of progenitor nodes\n",
    "- Given the 6 cell states (PGCLC, Endoderm, Endothelial, NMPs, Neural, Somitic), I will classify nodes using progenitor types of every combination of these cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ef97fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from the empty node info table\n",
    "node_info_FC = empty_node_info.copy()\n",
    "\n",
    "# For each node that is not a clone, record the progenitor type\n",
    "for clone in t.children:\n",
    "    for node in clone.traverse():\n",
    "        if not node.is_leaf():\n",
    "            leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "            node_info_FC.loc[node.name]['Progenitor Type'] = getProgenitorType_FC(leaves, cell_state_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e656804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary where the keys are each possible to record the actual values\n",
    "states = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "total_combinations = []\n",
    "for i in range(5):\n",
    "    for j in itertools.combinations(states, i+2):\n",
    "        total_combinations.append(j)\n",
    "\n",
    "progenitor_type_dict = {'PCGLC': set(['PCGLC']),\n",
    "                   'Endoderm': set(['Endoderm']),\n",
    "                   'Endothelial': set(['Endothelial']),\n",
    "                   'NMPs': set(['NMPs']),\n",
    "                   'Somitic': set(['Somitic']),\n",
    "                   'Neural': set(['Neural'])}\n",
    "for i in total_combinations:\n",
    "    label = '_'.join(i)\n",
    "    progenitor_type_dict[label] = set(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b7663e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endothelial_Somitic_Neural\n",
      "38\n",
      "PCGLC_Endoderm_Endothelial_Somitic_Neural\n",
      "11\n",
      "PCGLC_Endoderm_Endothelial_NMPs_Somitic_Neural\n",
      "5\n",
      "Endoderm_NMPs_Somitic_Neural\n",
      "6\n",
      "PCGLC_Endothelial_Somitic_Neural\n",
      "11\n",
      "Endoderm_Endothelial_NMPs_Somitic_Neural\n",
      "8\n",
      "Endoderm_Somitic_Neural\n",
      "38\n",
      "Endoderm_Endothelial_Somitic_Neural\n",
      "12\n",
      "Somitic_Neural\n",
      "179\n",
      "PCGLC_Endoderm_NMPs_Somitic_Neural\n",
      "1\n",
      "PCGLC_Endoderm_Somitic_Neural\n",
      "10\n",
      "PCGLC_NMPs_Somitic_Neural\n",
      "3\n",
      "PCGLC_Endoderm_Somitic\n",
      "9\n",
      "PCGLC\n",
      "32\n",
      "Endothelial_Somitic\n",
      "79\n",
      "PCGLC_Neural\n",
      "11\n",
      "PCGLC_Somitic\n",
      "10\n",
      "Somitic\n",
      "349\n",
      "Neural\n",
      "78\n",
      "PCGLC_Endoderm_Neural\n",
      "7\n",
      "Endoderm_Endothelial_Somitic\n",
      "11\n",
      "PCGLC_Somitic_Neural\n",
      "8\n",
      "Endoderm_Somitic\n",
      "52\n",
      "Endoderm_Neural\n",
      "9\n",
      "NMPs_Somitic\n",
      "4\n",
      "NMPs_Somitic_Neural\n",
      "8\n",
      "Endoderm_Endothelial_NMPs_Somitic\n",
      "3\n",
      "Endoderm\n",
      "10\n",
      "Endoderm_NMPs_Neural\n",
      "2\n",
      "PCGLC_Endothelial_NMPs_Somitic_Neural\n",
      "1\n",
      "PCGLC_NMPs_Somitic\n",
      "2\n",
      "PCGLC_Endoderm\n",
      "1\n",
      "PCGLC_Endothelial_Somitic\n",
      "3\n",
      "Endothelial_NMPs_Somitic_Neural\n",
      "1\n",
      "Endothelial_Neural\n",
      "2\n",
      "NMPs_Neural\n",
      "4\n",
      "Endothelial_NMPs_Somitic\n",
      "1\n",
      "Endothelial\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for progenitor in node_info_FC['Progenitor Type'].unique():\n",
    "    print(progenitor)\n",
    "    print(len(node_info_FC[node_info_FC['Progenitor Type'] == progenitor]['Clone Depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7636578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledBG(file_name = 'AM-DNA-098_full_set',\n",
    "           empty_node_info = empty_node_info,\n",
    "           cell_state_table = tree_cell_state_table,\n",
    "           node_leaf_dict = node_leaf_dict,\n",
    "           dropped_leaf_dict = {},\n",
    "           output_dir = '/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/',\n",
    "           FC = True,\n",
    "           numShuffles = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83f76f",
   "metadata": {},
   "source": [
    "# Plot all the progenitor combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "352ae68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n",
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n",
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n",
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n",
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n",
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n",
      "/usr/local/python/3.9.11-mmchan/lib/python3.9/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  plot_data = [np.asarray(s, float) for k, s in iter_data]\n"
     ]
    }
   ],
   "source": [
    "# Graph the countsfrom each distribution\n",
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_full_set_shuffledBG_Counts.txt', index_col = 0)\n",
    "\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_Node_Counts_FC.pdf')\n",
    "index_ranges = [(0, 10), (10, 19), (19, 28), (28, 37), (37, 46), (46, 55), (55, 63)]\n",
    "count = 1\n",
    "for i, j in index_ranges:\n",
    "    test = df_bgCounts.index[i: j]\n",
    "    fig, ax = plt.subplots(figsize = (15, 10))\n",
    "    sns.violinplot(data = df_bgCounts.T[test], ax = ax, scale = 'width', color = 'lightblue')\n",
    "    actual_values = []\n",
    "    for progenitor in test:\n",
    "        actual_values.append(len(node_info_FC[node_info_FC['Progenitor Type'] == progenitor]['Clone Depth']))\n",
    "    sns.swarmplot(x = test, y = actual_values, color = 'black', ax = ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Counts')\n",
    "    #plt.ylim(0, 225)\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    count += 1\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f4b3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the depth distributions of each progenitor type\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_full_set_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "    \n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_Node_Depths_FC.pdf')\n",
    "    \n",
    "# Graph the cdf plots from the dictionary\n",
    "count = 0\n",
    "for test in bgDists_dict.keys():\n",
    "    if count == 0:\n",
    "        fig, ax = plt.subplots(1, 4, figsize = (16, 4))\n",
    "        \n",
    "    temp_ax = ax[count]    \n",
    "\n",
    "    for i in bgDists_dict[test]:\n",
    "        sns.ecdfplot(i, ax=temp_ax, color = 'lightblue', alpha = 0.1)\n",
    "\n",
    "    if test in node_info_FC['Progenitor Type'].unique():\n",
    "        sns.ecdfplot(node_info_FC[node_info_FC['Progenitor Type'] == test]['Normalized Dist'], color = 'black', ax = temp_ax)\n",
    "        \n",
    "    temp_ax.set_title(test)\n",
    "    \n",
    "    if count == 3:\n",
    "        plt.tight_layout()\n",
    "        pp.savefig()\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        count = 0\n",
    "    else:\n",
    "        count += 1\n",
    "if count != 0:\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    plt.close()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a22c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_full_set_shuffledBG_Counts.txt', index_col = 0)\n",
    "df_bgVals = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_full_set_shuffledBG_Means.txt', index_col = 0)\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_full_set_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "\n",
    "# Make a table of actual count, mean BG count, std BG count, zscore, pval, actual dist mean, BG dist mean, BG dist std, zscore, pval\n",
    "values = ['Actual_Count', 'Mean_BG_Count', 'Std_BG_Count', 'zscore_Count', 'pval_L_Count', 'pval_U_Count', 'Actual_Dist', 'Mean_BG_Dist', 'Std_BG_Dist', 'zscore_Dist', 'pval_L_Dist', 'pval_U_Dist']\n",
    "\n",
    "progenitor_stats_FC = pd.DataFrame(index = bgDists_dict.keys(), columns = values)\n",
    "\n",
    "for progenitor in progenitor_stats_FC.index:\n",
    "    actualCount = len(node_info_FC[node_info_FC['Progenitor Type'] == progenitor]['Clone Depth'])\n",
    "    meanCount = df_bgCounts.loc[progenitor].mean()\n",
    "    stdCount = df_bgCounts.loc[progenitor].std()\n",
    "    zScore = (actualCount - meanCount) / stdCount\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above = []\n",
    "    below = []\n",
    "    equal = []\n",
    "    for i in df_bgCounts.loc[progenitor]:\n",
    "        if i > actualCount:\n",
    "            above.append(i)\n",
    "        elif i < actualCount:\n",
    "            below.append(i)\n",
    "        else:\n",
    "            equal.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower = (len(below) + len(equal)) / 500\n",
    "    pval_upper = (len(above) + len(equal)) / 500\n",
    "    \n",
    "    progenitor_stats_FC.loc[progenitor, 'Actual_Count'] = actualCount\n",
    "    progenitor_stats_FC.loc[progenitor, 'Mean_BG_Count'] = meanCount\n",
    "    progenitor_stats_FC.loc[progenitor, 'Std_BG_Count'] = stdCount\n",
    "    progenitor_stats_FC.loc[progenitor, 'zscore_Count'] = zScore\n",
    "    progenitor_stats_FC.loc[progenitor, 'pval_L_Count'] = pval_lower\n",
    "    progenitor_stats_FC.loc[progenitor, 'pval_U_Count'] = pval_upper\n",
    "    \n",
    "    # Record all the info for the normalized distributions\n",
    "    actualDist = node_info_FC[node_info_FC['Progenitor Type'] == progenitor]['Normalized Dist'].mean()\n",
    "    meanDist = df_bgVals.loc[progenitor + '_Mean'].mean()\n",
    "    stdDist = df_bgVals.loc[progenitor + '_Mean'].std()\n",
    "    zScoreDist = (actualDist - meanDist) / stdDist\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above_Dist = []\n",
    "    below_Dist = []\n",
    "    equal_Dist = []\n",
    "    for i in df_bgVals.loc[progenitor + '_Mean']:\n",
    "        if i > actualDist:\n",
    "            above_Dist.append(i)\n",
    "        elif i < actualDist:\n",
    "            below_Dist.append(i)\n",
    "        else:\n",
    "            equal_Dist.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower_Dist = (len(below_Dist) + len(equal_Dist)) / 500\n",
    "    pval_upper_Dist = (len(above_Dist) + len(equal_Dist)) / 500\n",
    "    \n",
    "    progenitor_stats_FC.loc[progenitor, 'Actual_Dist'] = actualDist\n",
    "    progenitor_stats_FC.loc[progenitor, 'Mean_BG_Dist'] = meanDist\n",
    "    progenitor_stats_FC.loc[progenitor, 'Std_BG_Dist'] = stdDist\n",
    "    progenitor_stats_FC.loc[progenitor, 'zscore_Dist'] = zScoreDist\n",
    "    progenitor_stats_FC.loc[progenitor, 'pval_L_Dist'] = pval_lower_Dist\n",
    "    progenitor_stats_FC.loc[progenitor, 'pval_U_Dist'] = pval_upper_Dist\n",
    "    \n",
    "progenitor_stats_FC.to_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/untrimmed_full_set/AM-DNA-098_Progenitor_Stats_FC.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297da685",
   "metadata": {},
   "source": [
    "# Trim the tree and Perform shuffledBG\n",
    "Trim nodes that occur in nested areas of the same type\n",
    "- If a branch stops differentiating in a path, then trim that whole branch down to 1 state\n",
    "- for example, if a somite committed node has 10 somite committed nodes under it, trim that branch down to just the top node\n",
    "- Remove all the cells that were in the trimmed region and replace them with 1 state (somite for example)\n",
    "- After performing this, calculate the actual values on the trimmed tree and perform the shuffledBG using the reduced cell states and tree\n",
    "\n",
    "trim the tree using the full set of nodes (all node types), then analyze it as the small or full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19d378e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp node_info table to perform the filtering on\n",
    "temp_node_info = empty_node_info.copy()\n",
    "\n",
    "# fill in the progenitor type info for the temp node info table using the full set of progenitor types\n",
    "for node in temp_node_info.index:\n",
    "    temp_node_info.loc[node, 'Progenitor Type'] = getProgenitorType_FC(node_leaf_dict[node], cell_state_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a3372eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column that records nodes that need trimming\n",
    "# These are nodes that are singular cell type progenitors that have subnodes that are also the same progenitor state\n",
    "# A singular cell type progenitor that only has leaves will not be changed\n",
    "temp_node_info['Trimmed'] = 'No'\n",
    "\n",
    "# Populate the column, Yes means that the node needs trimming, No means that it does not\n",
    "for node in temp_node_info.index:\n",
    "    trim = False\n",
    "\n",
    "    # Checks if the node is a singular cell type progenitor\n",
    "    if temp_node_info.loc[node, 'Progenitor Type'] in ['PCGLC', 'Neural', 'Somitic', 'Endoderm', 'Endothelial', 'NMPs']:\n",
    "        # If the subnode dictionary is not an empty list, then the node has subnodes\n",
    "        if node_subnode_dict[node] != []:\n",
    "            trim = True\n",
    "\n",
    "            # resets trim to false if any of the subnodes are not the same progenitor type\n",
    "            for subnode in node_subnode_dict[node]:\n",
    "                if temp_node_info.loc[node, 'Progenitor Type'] != temp_node_info.loc[subnode, 'Progenitor Type']:\n",
    "                    trim = False\n",
    "\n",
    "    if trim:\n",
    "        temp_node_info.loc[node, 'Trimmed'] = 'Yes'\n",
    "    else:\n",
    "        temp_node_info.loc[node, 'Trimmed'] = 'No'\n",
    "        \n",
    "# With this labeling, I will remove all leave and subnodes of these labeled nodes\n",
    "# some of these labeled nodes are subnodes of other labeled nodes, in which case only the top 'trimmed' node will be kept\n",
    "\n",
    "# Make a set that saves the nodes and leaves that need to be trimmed\n",
    "trimmed_nodes = set()\n",
    "trimmed_leaves = set()\n",
    "\n",
    "# Going through each node that was labeled for trimming, remove every subnode and leaf underneath that node\n",
    "for node in temp_node_info[temp_node_info['Trimmed'] == 'Yes'].index:\n",
    "    for subnode in node_subnode_dict[node]:\n",
    "        trimmed_nodes.add(subnode)\n",
    "    for leaf in node_leaf_dict[node]:\n",
    "        trimmed_leaves.add(leaf)\n",
    "        \n",
    "# Make a new node info table and a new empty node table after dropping the nodes\n",
    "trimmed_node_info = temp_node_info.drop(index = trimmed_nodes).copy()\n",
    "empty_trimmed_node_info = empty_node_info.drop(index = trimmed_nodes).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2675bc",
   "metadata": {},
   "source": [
    "# Calculate the actual progenitor values in the trimmed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b72018b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endothelial_Somitic_Neural\n",
      "\tUntrimmed:  38\n",
      "\ttrimmed:  38\n",
      "PCGLC_Endoderm_Endothelial_Somitic_Neural\n",
      "\tUntrimmed:  11\n",
      "\ttrimmed:  11\n",
      "PCGLC_Endoderm_Endothelial_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  5\n",
      "\ttrimmed:  5\n",
      "Endoderm_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  6\n",
      "\ttrimmed:  6\n",
      "PCGLC_Endothelial_Somitic_Neural\n",
      "\tUntrimmed:  11\n",
      "\ttrimmed:  11\n",
      "Endoderm_Endothelial_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  8\n",
      "\ttrimmed:  8\n",
      "Endoderm_Somitic_Neural\n",
      "\tUntrimmed:  38\n",
      "\ttrimmed:  38\n",
      "Endoderm_Endothelial_Somitic_Neural\n",
      "\tUntrimmed:  12\n",
      "\ttrimmed:  12\n",
      "Somitic_Neural\n",
      "\tUntrimmed:  179\n",
      "\ttrimmed:  179\n",
      "PCGLC_Endoderm_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  1\n",
      "\ttrimmed:  1\n",
      "PCGLC_Endoderm_Somitic_Neural\n",
      "\tUntrimmed:  10\n",
      "\ttrimmed:  10\n",
      "PCGLC_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  3\n",
      "\ttrimmed:  3\n",
      "PCGLC_Endoderm_Somitic\n",
      "\tUntrimmed:  9\n",
      "\ttrimmed:  9\n",
      "PCGLC\n",
      "\tUntrimmed:  32\n",
      "\ttrimmed:  16\n",
      "Endothelial_Somitic\n",
      "\tUntrimmed:  79\n",
      "\ttrimmed:  79\n",
      "PCGLC_Neural\n",
      "\tUntrimmed:  11\n",
      "\ttrimmed:  11\n",
      "PCGLC_Somitic\n",
      "\tUntrimmed:  10\n",
      "\ttrimmed:  10\n",
      "Somitic\n",
      "\tUntrimmed:  349\n",
      "\ttrimmed:  191\n",
      "Neural\n",
      "\tUntrimmed:  78\n",
      "\ttrimmed:  44\n",
      "PCGLC_Endoderm_Neural\n",
      "\tUntrimmed:  7\n",
      "\ttrimmed:  7\n",
      "Endoderm_Endothelial_Somitic\n",
      "\tUntrimmed:  11\n",
      "\ttrimmed:  11\n",
      "PCGLC_Somitic_Neural\n",
      "\tUntrimmed:  8\n",
      "\ttrimmed:  8\n",
      "Endoderm_Somitic\n",
      "\tUntrimmed:  52\n",
      "\ttrimmed:  52\n",
      "Endoderm_Neural\n",
      "\tUntrimmed:  9\n",
      "\ttrimmed:  9\n",
      "NMPs_Somitic\n",
      "\tUntrimmed:  4\n",
      "\ttrimmed:  4\n",
      "NMPs_Somitic_Neural\n",
      "\tUntrimmed:  8\n",
      "\ttrimmed:  8\n",
      "Endoderm_Endothelial_NMPs_Somitic\n",
      "\tUntrimmed:  3\n",
      "\ttrimmed:  3\n",
      "Endoderm\n",
      "\tUntrimmed:  10\n",
      "\ttrimmed:  8\n",
      "Endoderm_NMPs_Neural\n",
      "\tUntrimmed:  2\n",
      "\ttrimmed:  2\n",
      "PCGLC_Endothelial_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  1\n",
      "\ttrimmed:  1\n",
      "PCGLC_NMPs_Somitic\n",
      "\tUntrimmed:  2\n",
      "\ttrimmed:  2\n",
      "PCGLC_Endoderm\n",
      "\tUntrimmed:  1\n",
      "\ttrimmed:  1\n",
      "PCGLC_Endothelial_Somitic\n",
      "\tUntrimmed:  3\n",
      "\ttrimmed:  3\n",
      "Endothelial_NMPs_Somitic_Neural\n",
      "\tUntrimmed:  1\n",
      "\ttrimmed:  1\n",
      "Endothelial_Neural\n",
      "\tUntrimmed:  2\n",
      "\ttrimmed:  2\n",
      "NMPs_Neural\n",
      "\tUntrimmed:  4\n",
      "\ttrimmed:  4\n",
      "Endothelial_NMPs_Somitic\n",
      "\tUntrimmed:  1\n",
      "\ttrimmed:  1\n",
      "Endothelial\n",
      "\tUntrimmed:  4\n",
      "\ttrimmed:  4\n"
     ]
    }
   ],
   "source": [
    "for progenitor in trimmed_node_info['Progenitor Type'].unique():\n",
    "    print(progenitor)\n",
    "    print('\\tUntrimmed: ', len(node_info_FC[node_info_FC['Progenitor Type'] == progenitor]['Clone Depth']))\n",
    "    print('\\ttrimmed: ', len(trimmed_node_info[trimmed_node_info['Progenitor Type'] == progenitor]['Clone Depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182ea0d",
   "metadata": {},
   "source": [
    "# ShuffledBG on the trimmed small set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2f1949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the cell state table to be used for the shuffled background\n",
    "leaves_to_keep = []\n",
    "\n",
    "for cell in tree_cell_state_table['cellBC']:\n",
    "    if not cell in trimmed_leaves:\n",
    "        leaves_to_keep.append(cell)\n",
    "\n",
    "trimmed_tree_cell_state_table = tree_cell_state_table[tree_cell_state_table['cellBC'].isin(leaves_to_keep)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43c7c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also need to add in rows for the nodes that were the top of the trimming, these are the nodes that remain in the trimmed\n",
    "# node table that are labeled with a 'yes'\n",
    "\n",
    "# for the nodes that are kept at the top of the trimmed regions, I will assign them a cell type based on their classification\n",
    "# Since these are all singular progenitor types, I will assign them as 'PCGLC', 'Neural', etc\n",
    "temp_dict = {'Neural': 'NeuralTube1',\n",
    "            'Somitic': 'Somite',\n",
    "            'PCGLC': 'PCGLC',\n",
    "            'Endoderm': 'Endoderm',\n",
    "            'Endothelial': 'Endothelial',\n",
    "            'NMPs': 'NMPs'}\n",
    "\n",
    "\n",
    "# This adds back in ~66 nodes for the cells that were removed\n",
    "for node in trimmed_node_info[trimmed_node_info['Trimmed'] == 'Yes'].index:\n",
    "    cell_state = trimmed_node_info.loc[node, 'Progenitor Type']\n",
    "    trimmed_tree_cell_state_table.loc[node] = [temp_dict[cell_state], 'None', node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33456c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also need a dictionary that points each dropped leaf to the node in the trimmed_cell_state_table that saves it\n",
    "dropped_leaf_dict = {}\n",
    "\n",
    "# Add the trimmed leaves to the dict\n",
    "for leaf in trimmed_leaves:\n",
    "    dropped_leaf_dict[leaf] = \"\"\n",
    "    \n",
    "# go through remaining 'Yes' node and add that node as the item for each trimmed leaf\n",
    "for node in trimmed_node_info[trimmed_node_info['Trimmed'] == 'Yes'].index:\n",
    "    temp_leaves = node_leaf_dict[node]\n",
    "    \n",
    "    for leaf in temp_leaves:\n",
    "        # every leaf under these trimmed nodes should be in the trimmed leaf set, this will throw an error if this is not true\n",
    "        if dropped_leaf_dict[leaf] != '': \n",
    "            if dropped_leaf_dict[leaf] != node:\n",
    "                # Print an error if the leaf points to 2 seperate nodes (error in the code somewhere)\n",
    "                print('error')\n",
    "                print(dropped_leaf_dict[leaf])\n",
    "                break\n",
    "        # Set the value in the leaf dict to the top node\n",
    "        dropped_leaf_dict[leaf] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c2577c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledBG(file_name = 'AM-DNA-098_trimmed',\n",
    "           empty_node_info = empty_trimmed_node_info,\n",
    "           cell_state_table = trimmed_tree_cell_state_table,\n",
    "           node_leaf_dict = node_leaf_dict,\n",
    "           dropped_leaf_dict = dropped_leaf_dict,\n",
    "           output_dir = '/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/',\n",
    "           FC = False,\n",
    "           numShuffles = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cd4b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', 'PGCLC Progenitor', 'Endoderm Progenitor', 'Dropped']\n",
    "\n",
    "temp = trimmed_node_info.copy()\n",
    "\n",
    "# Get the actual values from the above node table\n",
    "for node in temp.index:\n",
    "    leaves = []\n",
    "    for leaf in node_leaf_dict[node]:\n",
    "        if leaf in dropped_leaf_dict.keys():\n",
    "            leaves.append(dropped_leaf_dict[leaf])\n",
    "        else:\n",
    "            leaves.append(leaf)\n",
    "    temp.loc[node]['Progenitor Type'] = getProgenitorType(leaves, trimmed_tree_cell_state_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd9ac7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_shuffledBG_Counts.txt', index_col = 0)\n",
    "\n",
    "actual_values = []\n",
    "for progenitor in order:\n",
    "    actual_values.append(len(temp[temp['Progenitor Type'] == progenitor]['Clone']))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 5))\n",
    "sns.violinplot(data = df_bgCounts.T, scale = 'width')\n",
    "sns.swarmplot(x = order, y = actual_values, color = 'Blue')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_Progenitor_Counts.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a55c15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "\n",
    "# Start a figure for the cdf plots for each progneitor type in the untrimmed not full combination dataset\n",
    "fig, ax = plt.subplots(2, 4, figsize = (16, 8))\n",
    "axes = [ax[0, 0], ax[0, 1], ax[0, 2], ax[0, 3], ax[1, 0], ax[1, 1], ax[1, 2], ax[1, 3]]\n",
    "\n",
    "count = 0\n",
    "for progenitor in bgDists_dict.keys():\n",
    "    temp_ax = axes[count]\n",
    "    count += 1\n",
    "    \n",
    "    for i in bgDists_dict[progenitor]:\n",
    "        sns.ecdfplot(i, ax=temp_ax, color = 'lightblue', alpha = 0.1)\n",
    "\n",
    "# Plot the actual data\n",
    "count = 0\n",
    "for progenitor in bgDists_dict.keys():\n",
    "    temp_ax = axes[count]\n",
    "    count += 1\n",
    "    \n",
    "    sns.ecdfplot(temp[temp['Progenitor Type'] == progenitor]['Normalized Dist'], ax = temp_ax, color = 'Black')\n",
    "    temp_ax.set_title(progenitor)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_Progenitor_cdfs.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "006c7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_shuffledBG_Counts.txt', index_col = 0)\n",
    "df_bgVals = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_shuffledBG_Means.txt', index_col = 0)\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "\n",
    "# Make a table of actual count, mean BG count, std BG count, zscore, pval, actual dist mean, BG dist mean, BG dist std, zscore, pval\n",
    "values = ['Actual_Count', 'Mean_BG_Count', 'Std_BG_Count', 'zscore_Count', 'pval_L_Count', 'pval_U_Count', 'Actual_Dist', 'Mean_BG_Dist', 'Std_BG_Dist', 'zscore_Dist', 'pval_L_Dist', 'pval_U_Dist']\n",
    "\n",
    "progenitor_stats_trim = pd.DataFrame(index = bgDists_dict.keys(), columns = values)\n",
    "\n",
    "for progenitor in progenitor_stats_trim.index:\n",
    "    actualCount = len(temp[temp['Progenitor Type'] == progenitor]['Clone Depth'])\n",
    "    meanCount = df_bgCounts.loc[progenitor].mean()\n",
    "    stdCount = df_bgCounts.loc[progenitor].std()\n",
    "    zScore = (actualCount - meanCount) / stdCount\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above = []\n",
    "    below = []\n",
    "    equal = []\n",
    "    for i in df_bgCounts.loc[progenitor]:\n",
    "        if i > actualCount:\n",
    "            above.append(i)\n",
    "        elif i < actualCount:\n",
    "            below.append(i)\n",
    "        else:\n",
    "            equal.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower = (len(below) + len(equal)) / 500\n",
    "    pval_upper = (len(above) + len(equal)) / 500\n",
    "    \n",
    "    progenitor_stats_trim.loc[progenitor, 'Actual_Count'] = actualCount\n",
    "    progenitor_stats_trim.loc[progenitor, 'Mean_BG_Count'] = meanCount\n",
    "    progenitor_stats_trim.loc[progenitor, 'Std_BG_Count'] = stdCount\n",
    "    progenitor_stats_trim.loc[progenitor, 'zscore_Count'] = zScore\n",
    "    progenitor_stats_trim.loc[progenitor, 'pval_L_Count'] = pval_lower\n",
    "    progenitor_stats_trim.loc[progenitor, 'pval_U_Count'] = pval_upper\n",
    "    \n",
    "    # Record all the info for the normalized distributions\n",
    "    actualDist = temp[temp['Progenitor Type'] == progenitor]['Normalized Dist'].mean()\n",
    "    meanDist = df_bgVals.loc[progenitor + '_Mean'].mean()\n",
    "    stdDist = df_bgVals.loc[progenitor + '_Mean'].std()\n",
    "    zScoreDist = (actualDist - meanDist) / stdDist\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above_Dist = []\n",
    "    below_Dist = []\n",
    "    equal_Dist = []\n",
    "    for i in df_bgVals.loc[progenitor + '_Mean']:\n",
    "        if i > actualDist:\n",
    "            above_Dist.append(i)\n",
    "        elif i < actualDist:\n",
    "            below_Dist.append(i)\n",
    "        else:\n",
    "            equal_Dist.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower_Dist = (len(below_Dist) + len(equal_Dist)) / 500\n",
    "    pval_upper_Dist = (len(above_Dist) + len(equal_Dist)) / 500\n",
    "    \n",
    "    progenitor_stats_trim.loc[progenitor, 'Actual_Dist'] = actualDist\n",
    "    progenitor_stats_trim.loc[progenitor, 'Mean_BG_Dist'] = meanDist\n",
    "    progenitor_stats_trim.loc[progenitor, 'Std_BG_Dist'] = stdDist\n",
    "    progenitor_stats_trim.loc[progenitor, 'zscore_Dist'] = zScoreDist\n",
    "    progenitor_stats_trim.loc[progenitor, 'pval_L_Dist'] = pval_lower_Dist\n",
    "    progenitor_stats_trim.loc[progenitor, 'pval_U_Dist'] = pval_upper_Dist\n",
    "    \n",
    "progenitor_stats_trim.to_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_small_set/AM-DNA-098_trimmed_Progenitor_Stats.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76219a43",
   "metadata": {},
   "source": [
    "# ShuffledBG on the trimmed nodes using the full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00a278ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the cell state table to be used for the shuffled background\n",
    "leaves_to_keep = []\n",
    "\n",
    "for cell in tree_cell_state_table['cellBC']:\n",
    "    if not cell in trimmed_leaves:\n",
    "        leaves_to_keep.append(cell)\n",
    "\n",
    "trimmed_tree_cell_state_table_FC = tree_cell_state_table[tree_cell_state_table['cellBC'].isin(leaves_to_keep)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c1803ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also need to add in rows for the nodes that were the top of the trimming, these are the nodes that remain in the trimmed\n",
    "# node table that are labeled with a 'yes'\n",
    "\n",
    "# for the nodes that are kept at the top of the trimmed regions, their node name is the singular cell type that they are \n",
    "# progenitors of, so that will be set in the table\n",
    "temp_dict = {'Neural': 'NeuralTube1',\n",
    "            'Somitic': 'Somite',\n",
    "            'PCGLC': 'PCGLC',\n",
    "            'Endoderm': 'Endoderm',\n",
    "            'Endothelial': 'Endothelial',\n",
    "            'NMPs': 'NMPs'}\n",
    "\n",
    "# This adds back in ~66 nodes for the cells that were removed\n",
    "for node in trimmed_node_info[trimmed_node_info['Trimmed'] == 'Yes'].index:\n",
    "    cell_state_FC = temp_dict[trimmed_node_info.loc[node, 'Progenitor Type']]\n",
    "    trimmed_tree_cell_state_table_FC.loc[node] = [cell_state_FC, 'None', node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0525f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also need a dictionary that points each dropped leaf to the node in the trimmed_cell_state_table that saves it\n",
    "dropped_leaf_dict_FC = {}\n",
    "\n",
    "# Add the trimmed leaves to the dict\n",
    "for leaf in trimmed_leaves:\n",
    "    dropped_leaf_dict_FC[leaf] = \"\"\n",
    "    \n",
    "# go through remaining 'Yes' node and add that node as the item for each trimmed leaf\n",
    "for node in trimmed_node_info[trimmed_node_info['Trimmed'] == 'Yes'].index:\n",
    "    temp_leaves = node_leaf_dict[node]\n",
    "    \n",
    "    for leaf in temp_leaves:\n",
    "        # every leaf under these trimmed nodes should be in the trimmed leaf set, this will throw an error if this is not true\n",
    "        if dropped_leaf_dict_FC[leaf] != '': \n",
    "            if dropped_leaf_dict_FC[leaf] != node:\n",
    "                # Print an error if the leaf points to 2 seperate nodes (error in the code somewhere)\n",
    "                print('error')\n",
    "                print(dropped_leaf_dict_FC[leaf])\n",
    "                break\n",
    "        # Set the value in the leaf dict to the top node\n",
    "        dropped_leaf_dict_FC[leaf] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51f5270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledBG(file_name = 'AM-DNA-098_trimmed_FC',\n",
    "           empty_node_info = empty_trimmed_node_info,\n",
    "           cell_state_table = trimmed_tree_cell_state_table_FC,\n",
    "           node_leaf_dict = node_leaf_dict,\n",
    "           dropped_leaf_dict = dropped_leaf_dict,\n",
    "           output_dir = '/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/',\n",
    "           FC = True,\n",
    "           numShuffles = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8143ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the countsfrom each distribution\n",
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/AM-DNA-098_trimmed_FC_shuffledBG_Counts.txt', index_col = 0)\n",
    "\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/AM-DNA-098_trimmed_Node_Counts_FC.pdf')\n",
    "index_ranges = [(0, 10), (10, 19), (19, 28), (28, 37), (37, 46), (46, 55), (55, 63)]\n",
    "count = 1\n",
    "for i, j in index_ranges:\n",
    "    test = df_bgCounts.index[i: j]\n",
    "    fig, ax = plt.subplots(figsize = (15, 10))\n",
    "    sns.violinplot(data = df_bgCounts.T[test], ax = ax, scale = 'width', color = 'lightblue')\n",
    "    actual_values = []\n",
    "    for progenitor in test:\n",
    "        actual_values.append(len(node_info_FC[node_info_FC['Progenitor Type'] == progenitor]['Clone Depth']))\n",
    "    sns.swarmplot(x = test, y = actual_values, color = 'black', ax = ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Counts')\n",
    "    #plt.ylim(0, 225)\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    count += 1\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83085f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bgCounts = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/AM-DNA-098_trimmed_FC_shuffledBG_Counts.txt', index_col = 0)\n",
    "df_bgVals = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/AM-DNA-098_trimmed_FC_shuffledBG_Means.txt', index_col = 0)\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/AM-DNA-098_trimmed_FC_shuffledBG_Distributions.pickle', 'rb') as f:\n",
    "    bgDists_dict = pickle.load(f)\n",
    "\n",
    "# Make a table of actual count, mean BG count, std BG count, zscore, pval, actual dist mean, BG dist mean, BG dist std, zscore, pval\n",
    "values = ['Actual_Count', 'Mean_BG_Count', 'Std_BG_Count', 'zscore_Count', 'pval_L_Count', 'pval_U_Count', 'Actual_Dist', 'Mean_BG_Dist', 'Std_BG_Dist', 'zscore_Dist', 'pval_L_Dist', 'pval_U_Dist']\n",
    "\n",
    "progenitor_stats_trim_FC = pd.DataFrame(index = bgDists_dict.keys(), columns = values)\n",
    "\n",
    "for progenitor in progenitor_stats_trim_FC.index:\n",
    "    actualCount = len(trimmed_node_info[trimmed_node_info['Progenitor Type'] == progenitor]['Clone Depth'])\n",
    "    meanCount = df_bgCounts.loc[progenitor].mean()\n",
    "    stdCount = df_bgCounts.loc[progenitor].std()\n",
    "    zScore = (actualCount - meanCount) / stdCount\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above = []\n",
    "    below = []\n",
    "    equal = []\n",
    "    for i in df_bgCounts.loc[progenitor]:\n",
    "        if i > actualCount:\n",
    "            above.append(i)\n",
    "        elif i < actualCount:\n",
    "            below.append(i)\n",
    "        else:\n",
    "            equal.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower = (len(below) + len(equal)) / 500\n",
    "    pval_upper = (len(above) + len(equal)) / 500\n",
    "    \n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'Actual_Count'] = actualCount\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'Mean_BG_Count'] = meanCount\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'Std_BG_Count'] = stdCount\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'zscore_Count'] = zScore\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'pval_L_Count'] = pval_lower\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'pval_U_Count'] = pval_upper\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Record all the info for the normalized distributions\n",
    "    actualDist = trimmed_node_info[trimmed_node_info['Progenitor Type'] == progenitor]['Normalized Dist'].mean()\n",
    "    meanDist = df_bgVals.loc[progenitor + '_Mean'].mean()\n",
    "    stdDist = df_bgVals.loc[progenitor + '_Mean'].std()\n",
    "    zScoreDist = (actualDist - meanDist) / stdDist\n",
    "    \n",
    "    # split the distribution into classes of above, below, or equal to the actual value\n",
    "    above_Dist = []\n",
    "    below_Dist = []\n",
    "    equal_Dist = []\n",
    "    for i in df_bgVals.loc[progenitor + '_Mean']:\n",
    "        if i > actualDist:\n",
    "            above_Dist.append(i)\n",
    "        elif i < actualDist:\n",
    "            below_Dist.append(i)\n",
    "        else:\n",
    "            equal_Dist.append(i)\n",
    "    \n",
    "    # this is the pval that the actual value is lower than the distribution, calculated as # of \n",
    "    pval_lower_Dist = (len(below_Dist) + len(equal_Dist)) / 500\n",
    "    pval_upper_Dist = (len(above_Dist) + len(equal_Dist)) / 500\n",
    "    \n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'Actual_Dist'] = actualDist\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'Mean_BG_Dist'] = meanDist\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'Std_BG_Dist'] = stdDist\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'zscore_Dist'] = zScoreDist\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'pval_L_Dist'] = pval_lower_Dist\n",
    "    progenitor_stats_trim_FC.loc[progenitor, 'pval_U_Dist'] = pval_upper_Dist\n",
    "    \n",
    "progenitor_stats_trim_FC.to_csv('/Genomics/chanlab/blaw/TLS/data/AM-DNA-098/shuffledBG/trimmed_full_set/AM-DNA-098_trimmed_FC_Progenitor_Stats.txt', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

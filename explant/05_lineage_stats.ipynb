{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scanpy as sc\n",
    "import cassiopeia as cas\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from itertools import combinations\n",
    "from itertools import product\n",
    "from ete3 import Tree\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f3eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterColorsFile = \"/Genomics/chanlab/mchan/Adriano/TLS/TLS_TLSCL/20211102_clusterColorsTLSCL.p\"\n",
    "with open(clusterColorsFile,'rb') as fp:\n",
    "    colorDict = pickle.load(fp)\n",
    "    \n",
    "barcodes = ['Bar1', 'Bar2', 'Bar3', 'Bar4', 'Bar5', 'Bar6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576804c",
   "metadata": {},
   "source": [
    "# Fill out metadata for trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307338ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxDepth(node):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "    returns:\n",
    "        - The max depth of any branch in that node\n",
    "    '''\n",
    "    if node.is_leaf():\n",
    "        return 0\n",
    "    children_depths = []\n",
    "    \n",
    "    for child in node.children:\n",
    "        test = maxDepth(child)\n",
    "        \n",
    "        children_depths.append(test)\n",
    "        \n",
    "    return max(children_depths) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9811a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_combo = []\n",
    "for barcode in barcodes:\n",
    "    for time in ['120', '144', '120_144']:\n",
    "        for method in ['hybrid', 'greedy', 'neighbor']:\n",
    "            tree_combo.append('{}_{}_{}'.format(barcode, time, method))\n",
    "\n",
    "explant_metadata = pd.DataFrame(index = tree_combo, columns = ['barcode', 'timepoint', 'method', 'n_of_cells', 'n_of_clones', 'max_clone_depth', 'avg_clone_depth', 'avg_clone_size', 'tree_likelihood', 'n_of_unique_alleles', 'n_of_unique_indels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95fc0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out the metadata table\n",
    "for barcode in barcodes:\n",
    "    for time in ['120', '144', '120_144']:\n",
    "        for method in ['greedy', 'neighbor', 'hybrid']:\n",
    "            ID = '{}_{}_{}'.format(barcode, time, method)\n",
    "            \n",
    "            nwkFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/{}/{}/{}_{}_{}_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, time, method, barcode, time, method)\n",
    "            metadataFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/{}/{}/{}_{}_metadata.txt'.format(barcode, time, method, barcode, time)\n",
    "            characterFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/{}/{}/{}_{}_character_matrix.txt'.format(barcode, time, method, barcode, time)\n",
    "            prior_file = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/{}/{}/{}_{}_priors.pickle'.format(barcode, time, method, barcode, time)\n",
    "\n",
    "            temp_allele_table_file = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/{}/{}_{}_allele_table.txt'.format(barcode, time, barcode, time)\n",
    "            temp_allele_table = pd.read_csv(temp_allele_table_file, index_col = 0)\n",
    "            \n",
    "            t = Tree(nwkFile, format=1)\n",
    "            tree_meta = pd.read_csv(metadataFile, sep='\\t')\n",
    "            character_matrix = pd.read_csv(characterFile, sep='\\t', index_col = 0)\n",
    "            with open(prior_file, 'rb') as f:\n",
    "                priors = pickle.load(f)\n",
    "\n",
    "            tree = cas.data.CassiopeiaTree(character_matrix=character_matrix, priors=priors, tree = t)\n",
    "\n",
    "            missing_proportion = (character_matrix == -1).sum(axis=0) / character_matrix.shape[0]\n",
    "            uncut_proportion = (character_matrix == 0).sum(axis=0) / character_matrix.shape[0]\n",
    "            n_unique_states = character_matrix.apply(lambda x: len(np.unique(x[(x != 0) & (x != -1)])), axis=0)\n",
    "            tree.parameters['stochastic_missing_probability'] = 0.1\n",
    "            \n",
    "            temp_clones = {}\n",
    "            clone_sizes = []\n",
    "            clone_depths = []\n",
    "            for clone in t.children:\n",
    "                temp_clones[clone.name] = [leaf.name for leaf in clone.get_leaves()]\n",
    "                clone_sizes.append(len(temp_clones[clone.name]))\n",
    "                clone_depths.append(maxDepth(clone))\n",
    "                \n",
    "            unique_alleles = set()\n",
    "            unique_indels = set()\n",
    "            for allele in temp_allele_table['allele']:\n",
    "                unique_alleles.add(allele)\n",
    "            for indel in temp_allele_table['r1']:\n",
    "                unique_indels.add(indel)\n",
    "            for indel in temp_allele_table['r2']:\n",
    "                unique_indels.add(indel)\n",
    "            for indel in temp_allele_table['r3']:\n",
    "                unique_indels.add(indel)\n",
    "\n",
    "            n_of_unique_lineageBC = len(unique_lineageBC)\n",
    "            n_of_unique_alleles = len(unique_alleles)\n",
    "            n_of_unique_indels = len(unique_indels)\n",
    "            \n",
    "                        \n",
    "            explant_metadata.loc[ID, 'barcode'] = barcode\n",
    "            explant_metadata.loc[ID, 'timepoint'] = time\n",
    "            explant_metadata.loc[ID, 'method'] = method\n",
    "            explant_metadata.loc[ID, 'n_of_cells'] = len(t.get_leaves())\n",
    "            explant_metadata.loc[ID, 'max_clone_depth'] = maxDepth(t)\n",
    "            explant_metadata.loc[ID, 'n_of_clones'] = len(t.children)\n",
    "            explant_metadata.loc[ID, 'avg_clone_depth'] = np.mean(clone_depths)\n",
    "            explant_metadata.loc[ID, 'avg_clone_size'] = np.mean(clone_sizes)\n",
    "            explant_metadata.loc[ID, 'likelihood'] = cas.tools.calculate_likelihood_continuous(tree)\n",
    "            explant_metadata.loc[ID, 'n_of_unique_alleles'] = n_of_unique_alleles\n",
    "            explant_metadata.loc[ID, 'n_of_unique_indels'] = n_of_unique_indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14309d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "explant_metadata.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/lineage/lineage_stats/explant_metadata.txt', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

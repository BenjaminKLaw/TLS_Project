{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5447d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scanpy as sc\n",
    "import cassiopeia as cas\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "from matplotlib.pyplot import rc_context\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from ete3 import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c3daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterColorsFile = \"/Genomics/chanlab/mchan/Adriano/TLS/TLS_TLSCL/20211102_clusterColorsTLSCL.p\"\n",
    "with open(clusterColorsFile,'rb') as fp:\n",
    "    colorDict = pickle.load(fp)\n",
    "\n",
    "# Load the cell state table\n",
    "cell_state_table = pd.read_csv('/Genomics/chanlab/blaw/TLS/metadata/TLS_Explant_Total_cellBC_cellState.tsv', sep='\\t')\n",
    "\n",
    "barcodes = ['Bar1', 'Bar2', 'Bar3', 'Bar4', 'Bar5', 'Bar6']\n",
    "progenitor_list = ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', 'PGCLC Progenitor', 'Endoderm Progenitor', 'Dropped']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4b179",
   "metadata": {},
   "source": [
    "# Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a81770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxDepth(node):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "    returns:\n",
    "        - The max depth of any branch in that node\n",
    "    '''\n",
    "    if node.is_leaf():\n",
    "        return 0\n",
    "    children_depths = []\n",
    "    \n",
    "    for child in node.children:\n",
    "        test = maxDepth(child)\n",
    "        \n",
    "        children_depths.append(test)\n",
    "        \n",
    "    return max(children_depths) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba32ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProgenitorType(leaves, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a list of leaves that are extant cells for a node\n",
    "        - a table that contains the annotated cell state for each cellBC\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    - Extended progenitors: PGCs, Endoderm, Somitic, Neural\n",
    "    - Pluripotent progenitors: Endoderm, Somitic, Neural\n",
    "    - Bipotent progenitors: Somitic, Neural (both if contains or not NMPs still count)\n",
    "    - Endoderm progenitors: Endoderm only\n",
    "    - PGCLC progenitors: PGCLC only\n",
    "    - Somitic progenitors: somitic only\n",
    "    - Neural progenitors: neural only\n",
    "    \n",
    "    Neural class is made from NeuralTube1 and NeuralTube2\n",
    "    Somite class is pPSM, aPSM, Somite-1, Somite0, Somite, Somite1, SomiteSclero, SomiteDermo\n",
    "    \n",
    "    NMPs are left out of the analysis. +/- an NMP does not change the category that a node gets\n",
    "    \n",
    "    exclude nodes that are Endoderm without both somitic and neural (unless it is alone)\n",
    "    exclude nodes that are PGC without all 3 endoderm, somitic, and neural (unless it is alone)\n",
    "    \n",
    "    Endothelial is allowed (+/-) in extended progenitors and pluripotent progenitors\n",
    "    Endothelial is not allowed (-) in all other progenitors\n",
    "    \n",
    "    Unassigned / Unknown cells are not looked at for this classification (+/-)\n",
    "    \n",
    "    I am changing this analysis to also record if a node is exclusively NMP (self renewing NMP)\n",
    "    \n",
    "    '''\n",
    "    progenitor_types = {'Extended Progenitor': set(['PCGLC', 'Endoderm', 'Somitic', 'Neural']),\n",
    "                        'Pluripotent Progenitor': set(['Endoderm', 'Somitic', 'Neural']),\n",
    "                        'Bipotent Progenitor' : set(['Somitic', 'Neural']),\n",
    "                        'Endoderm Progenitor': set(['Endoderm']),\n",
    "                        'PGCLC Progenitor': set(['PCGLC']),\n",
    "                        'Somitic Progenitor': set(['Somitic']),\n",
    "                        'Neural Progenitor': set(['Neural'])}\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "    \n",
    "    #if set(cell_types) == set(['NMPs']):\n",
    "     #   return 'Self Renewing NMP'\n",
    "    \n",
    "    # Group the cell states into neural and somite categories\n",
    "    grouped_states = []\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            grouped_states.append('Somitic')\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            grouped_states.append('Neural')\n",
    "        elif state in ['PCGLC', 'Endoderm', 'Endothelial']:\n",
    "            grouped_states.append(state)\n",
    "    \n",
    "    state_set = set(grouped_states)\n",
    "    \n",
    "    for progenitor in progenitor_types.keys():\n",
    "        if state_set == progenitor_types[progenitor]:\n",
    "            return progenitor\n",
    "    if state_set == set(['PCGLC', 'Endoderm', 'Somitic', 'Neural', 'Endothelial']):\n",
    "        return 'Extended Progenitor'\n",
    "    if state_set == set(['Endoderm', 'Somitic', 'Neural', 'Endothelial']):\n",
    "        return 'Pluripotent Progenitor'\n",
    "    \n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7eb55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProgenitorType_FC(leaves, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a tree node to test\n",
    "        - a table that contains the annotated cell state for each cellBC\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    Record the cell states that are connected to a node from the following 6 states:\n",
    "    - PGCLC\n",
    "    - Endoderm\n",
    "    - Endothelial\n",
    "    - NMPs\n",
    "    - Somitic\n",
    "    - Neural\n",
    "    \n",
    "    Neural class is made from NeuralTube1 and NeuralTube2\n",
    "    Somite class is pPSM, aPSM, Somite-1, Somite0, Somite, Somite1, SomiteSclero, SomiteDermo\n",
    "    \n",
    "    Unassigned / Unknown cells are not looked at for this classification (+/-)\n",
    "    \n",
    "    '''\n",
    "    states = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "    total_combinations = []\n",
    "    for i in range(5):\n",
    "        for j in itertools.combinations(states, i+2):\n",
    "            total_combinations.append(j)\n",
    "\n",
    "    progenitor_type_dict = {'PCGLC': set(['PCGLC']),\n",
    "                       'Endoderm': set(['Endoderm']),\n",
    "                       'Endothelial': set(['Endothelial']),\n",
    "                       'NMPs': set(['NMPs']),\n",
    "                       'Somitic': set(['Somitic']),\n",
    "                       'Neural': set(['Neural'])}\n",
    "    for i in total_combinations:\n",
    "        label = '_'.join(i)\n",
    "        progenitor_type_dict[label] = set(i)\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "    \n",
    "    # Group the cell states into neural and somite categories\n",
    "    grouped_states = []\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            grouped_states.append('Somitic')\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            grouped_states.append('Neural')\n",
    "        elif state in ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs']:\n",
    "            grouped_states.append(state)\n",
    "    \n",
    "    state_set = set(grouped_states)\n",
    "    \n",
    "    for progenitor in progenitor_type_dict.keys():\n",
    "        if state_set == progenitor_type_dict[progenitor]:\n",
    "            return progenitor\n",
    "    \n",
    "    # Return dropped if a node is not in the progenitor type dict\n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8332c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeType(leaves, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a list of leaves that are extant cells for a node\n",
    "        - a table that contains the annotated timepoint for each cellBC in a 'timepoint' column\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    Record the timepoints for each extant cell for the given node (the leaves):\n",
    "        - 120h\n",
    "        - 144h\n",
    "    \n",
    "    returns one of the 3 following time types:\n",
    "        - 120\n",
    "        - 144\n",
    "        - 120_144\n",
    "    \n",
    "    '''\n",
    "    states = ['120', '144']\n",
    "\n",
    "    time_type_dict = {'120': set(['120']),\n",
    "                       '144': set(['144']),\n",
    "                       '120_144': set(['120', '144'])}\n",
    "    \n",
    "    grouped_states = [str(i) for i in cell_state_table[cell_state_table['cellBC'].isin(leaves)]['timepoint'].to_list()]\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    state_set = set(grouped_states)\n",
    "\n",
    "    for time_type in time_type_dict.keys():\n",
    "        if state_set == time_type_dict[time_type]:\n",
    "            return time_type\n",
    "    \n",
    "    # Return dropped if a node is not in the progenitor type dict\n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe811fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTimepoint(leaves, cell_state_table):\n",
    "    '''\n",
    "    Input:\n",
    "        - a leaf in the tree. Assumed to be a str that has a value in the cell state table\n",
    "    return:\n",
    "        - A tuple of the number of 120h and 144h cells for the node\n",
    "    '''\n",
    "    #leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "\n",
    "    # Group the Neural and Somite cell states into 1 category and remove PGCLC, Endoderm, Unknown, Epithelial\n",
    "    count_120 = 0\n",
    "    count_144 = 0\n",
    "    temp = cell_state_table.copy()\n",
    "    temp.set_index('cellBC', inplace = True)\n",
    "    for cell in leaves:\n",
    "        time = temp.loc[cell, 'timepoint']\n",
    "        if time == 120:\n",
    "            count_120 += 1\n",
    "        elif time == 144:\n",
    "            count_144 += 1\n",
    "\n",
    "    return (count_120, count_144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80749c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffledBG (file_name, empty_node_info, cell_state_table, node_leaf_dict, dropped_leaf_dict, output_dir, FC = False, numShuffles = 500):\n",
    "    '''\n",
    "    input:\n",
    "        file_name - an experiment name for saving the files\n",
    "        empty_node_info - a table that contains all the nodes in the tree as indexes and a 'Progenitor Type' column to be populated\n",
    "        cell_state_table - a table that contains the assigned cell state for each cell in the tree. Any nodes that are added \n",
    "            back after the trimming (keeping the top node of a nest set) should be added into these columns. This table should\n",
    "            ONLY contain cells that are present on the tree / node table so that the shuffling is accurate\n",
    "        node_leaf_dict - a dictionary that saves a list of leaves that are extant cells for a given node (key)\n",
    "        dropped_leaf_dict - a dictionary that saves the cells that are removed from the tree (via trimming) as keys and the \n",
    "            new node values as values to be looked up in the cell state table\n",
    "        output_dir - a file path to a directory to save the files and graphs\n",
    "        FC - a boolean to use the full combination of progenitor states or the smaller subset (default to False)\n",
    "        shuffles - the number of iterations to do the shuffled BG (default to 500)\n",
    "    output:\n",
    "        df_bgCounts - a dataframe of the counts for each progenitor state in each iteration of the shuffledBG \n",
    "            (saved as a csv file to output_dir)\n",
    "        df_bgVals - a dataframe of the mean and median of normalized depth for each progenitor state for each itr\n",
    "            (saved as a csv file to output_dir)\n",
    "        bgDist_dict - a dictionary that saves a list of arrays of normalized depth for each progenitor state for each itr\n",
    "            (saved as a pickle .p file to output_dir)\n",
    "    '''\n",
    "    # check if the output_dir is real\n",
    "    if not os.path.exists(output_dir):\n",
    "        print('output_dir path does not exists')\n",
    "        return\n",
    "    \n",
    "    # shuffle background and calculate the # of each progenitor type for the entire dataset\n",
    "    itrList = ['itr' + str(i) for i in range(numShuffles)]\n",
    "    \n",
    "    # set a dictionary of the progenitor types based on the full set of progenitor types or the reduced set\n",
    "    if FC:\n",
    "        states = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "        progenitor_types = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "        for i in range(5):\n",
    "            for j in itertools.combinations(states, i+2):\n",
    "                progenitor_types.append('_'.join(j))\n",
    "    else:\n",
    "        progenitor_types = ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', 'PGCLC Progenitor', 'Endoderm Progenitor', 'Dropped']\n",
    "    \n",
    "\n",
    "    indexList = []\n",
    "    for progenitor in progenitor_types:\n",
    "        for i in ['Mean', 'Median']:\n",
    "            indexList.append(progenitor + '_' + i)\n",
    "    \n",
    "    # initialize the 3 variables to save the results\n",
    "    df_bgCounts = pd.DataFrame(index = progenitor_types, columns = itrList)\n",
    "    df_bgVals = pd.DataFrame(index = indexList, columns = itrList)\n",
    "    bgDists_dict = {}\n",
    "\n",
    "    for itr in range(numShuffles):\n",
    "        # Assign a temp node_info table with progenitor types not classified\n",
    "        node_info_itr = empty_node_info.copy()\n",
    "\n",
    "        # Randomly shuffle the cell_state annotations in a cell state table\n",
    "        shuffled_cell_state_table = cell_state_table.copy()\n",
    "        shuffled_cell_state_table['cell_state'] = shuffled_cell_state_table['cell_state'].sample(frac = 1).values\n",
    "\n",
    "        # fill the node_info_itr table with node classifications using the shuffled cell state table\n",
    "        for node in node_info_itr.index:\n",
    "            leaves = []\n",
    "            for leaf in node_leaf_dict[node]:\n",
    "                if leaf in dropped_leaf_dict.keys():\n",
    "                    leaves.append(dropped_leaf_dict[leaf])\n",
    "                else:\n",
    "                    leaves.append(leaf)\n",
    "            if FC:\n",
    "                node_info_itr.loc[node]['Progenitor Type'] = getProgenitorType_FC(leaves, shuffled_cell_state_table)\n",
    "            else:\n",
    "                node_info_itr.loc[node]['Progenitor Type'] = getProgenitorType(leaves, shuffled_cell_state_table)\n",
    "\n",
    "        for progenitor in progenitor_types:\n",
    "            df_bgCounts.loc[progenitor, 'itr{}'.format(itr)] = len(node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Clone'])  \n",
    "\n",
    "        for progenitor in progenitor_types:\n",
    "            # assign the mean and median to be 0 if the node type was not observed in this iteration\n",
    "            if df_bgCounts.loc[progenitor, 'itr{}'.format(itr)] > 0:\n",
    "                df_bgVals.loc[progenitor + '_Mean', 'itr{}'.format(itr)] = node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Normalized Dist'].mean()\n",
    "                df_bgVals.loc[progenitor + '_Median', 'itr{}'.format(itr)] = node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Normalized Dist'].median()\n",
    "            else:\n",
    "                df_bgVals.loc[progenitor + '_Mean', 'itr{}'.format(itr)] = 0\n",
    "                df_bgVals.loc[progenitor + '_Median', 'itr{}'.format(itr)] = 0\n",
    "\n",
    "        for progenitor in progenitor_types:\n",
    "            # check if this progenitor has not been added to the dict yet\n",
    "            if progenitor not in bgDists_dict.keys():\n",
    "                bgDists_dict[progenitor] = []\n",
    "\n",
    "            # If the progenitor is observed in this iteration, then add the array of normalized depths to the list\n",
    "            if df_bgCounts.loc[progenitor, 'itr{}'.format(itr)] > 0:\n",
    "                bgDists_dict[progenitor].append(node_info_itr[node_info_itr['Progenitor Type'] == progenitor]['Normalized Dist'])\n",
    "\n",
    "                \n",
    "    # Save the 3 objects\n",
    "    with open(output_dir + '{}_shuffledBG_Distributions.pickle'.format(file_name), 'wb') as handle:\n",
    "        pickle.dump(bgDists_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    df_bgVals.to_csv(output_dir + '{}_shuffledBG_Means.txt'.format(file_name))\n",
    "\n",
    "    df_bgCounts.to_csv(output_dir + '{}_shuffledBG_Counts.txt'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7118415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffledBG_time (file_name, tree, empty_node_info, cell_state_table, node_leaf_dict, dropped_leaf_dict, output_dir, single_cell_clones = True, numShuffles = 500):\n",
    "    '''\n",
    "    input:\n",
    "        file_name - an experiment name string for saving the files\n",
    "        tree - an ete tree for the tree. Assumed to have all the same nodes and leaves in the node info and cell state table\n",
    "        empty_node_info - a table that contains all the nodes in the tree as indexes and a 'Node Time' column to be populated\n",
    "        cell_state_table - a table that contains the assigned cell state for each cell in the tree. Any nodes that are added \n",
    "            back after the trimming (keeping the top node of a nest set) should be added into these columns. This table should\n",
    "            ONLY contain cells that are present on the tree / node table so that the shuffling is accurate\n",
    "        node_leaf_dict - a dictionary that saves a list of leaves that are extant cells for a given node (key)\n",
    "        dropped_leaf_dict - a dictionary that saves the cells that are removed from the tree (via trimming) as keys and the \n",
    "            new node values as values to be looked up in the cell state table\n",
    "        output_dir - a file path to a directory to save the files and graphs\n",
    "        single_cell_clones - a boolean to determine if single cell clones should be counted. Default is yes\n",
    "        numShuffles - the number of iterations to do the shuffled BG (default to 500)\n",
    "    output:\n",
    "        df_bgCounts - a dataframe of the counts for each time state in each iteration of the shuffledBG \n",
    "            (saved as a csv file to output_dir)\n",
    "        df_bgClones - a dataframe that counts the # of clones in each timepoint / iteration\n",
    "        node_depths - a dictionary that saves the depths of all nodes in each timepoint / iteration\n",
    "        clone_sizes - a dictionary that saves the sizes (# of cells) of each clone in each timepoint / iteration\n",
    "        clone_depths - a dictionary that saves the max clone dpeth for each clone in each timepoint / iteration\n",
    "    '''\n",
    "    # check if the output_dir is real\n",
    "    if not os.path.exists(output_dir):\n",
    "        print('output_dir path does not exists')\n",
    "        return\n",
    "    \n",
    "    # shuffle background and calculate the # of each time type for the entire dataset\n",
    "    itrList = ['itr' + str(i) for i in range(numShuffles)]\n",
    "    \n",
    "    # set a dictionary of the time types based on the full set of time types or the reduced set\n",
    "    time_types = ['120', '144', '120_144']\n",
    "    \n",
    "\n",
    "    indexList = []\n",
    "    for time in time_types:\n",
    "        for i in ['Mean', 'Median']:\n",
    "            indexList.append(time + '_' + i)\n",
    "    \n",
    "    # initialize the dataframes and dictionaries to save the results\n",
    "    # records the # of nodes in each timepoint for each iteration\n",
    "    df_bgCounts = pd.DataFrame(index = time_types, columns = itrList)\n",
    "    # records the # of clones in each timepoint for each iteration\n",
    "    df_bgClones = pd.DataFrame(index = time_types, columns = itrList)\n",
    "    \n",
    "    # records the distribution of sizes and depths for clones in each timepoint in each iteration\n",
    "    node_depths = {}\n",
    "    clone_sizes = {}\n",
    "    clone_depths = {}\n",
    "    for time in time_types:\n",
    "        clone_sizes[time] = []\n",
    "        clone_depths[time] = []\n",
    "        node_depths[time] = []\n",
    "\n",
    "    for itr in range(numShuffles):\n",
    "        # Assign a temp node_info table with time types not classified\n",
    "        node_info_itr = empty_node_info.copy()\n",
    "\n",
    "        # Randomly shuffle the timepoint annotations in the cell state table\n",
    "        shuffled_cell_state_table = cell_state_table.copy()\n",
    "        shuffled_cell_state_table['timepoint'] = shuffled_cell_state_table['timepoint'].sample(frac = 1).values\n",
    "\n",
    "        # fill the node_info_itr table with node classifications using the shuffled cell state table\n",
    "        for node in node_info_itr.index:\n",
    "            leaves = []\n",
    "            for leaf in node_leaf_dict[node]:\n",
    "                if leaf in dropped_leaf_dict.keys():\n",
    "                    leaves.append(dropped_leaf_dict[leaf])\n",
    "                else:\n",
    "                    leaves.append(leaf)\n",
    "            \n",
    "            node_info_itr.loc[node]['node_time'] = getTimeType(leaves, shuffled_cell_state_table)\n",
    "            \n",
    "        if single_cell_clones:\n",
    "            # get a list of clones from the tree\n",
    "            clones = [clone.name for clone in t.children]\n",
    "        else:\n",
    "            # get a list of clones from the node table. This removes single cell 'clones' since they don't have nodes\n",
    "            clones = node_info_itr[node_info_itr['dist_to_clone'] == 0].index\n",
    "        \n",
    "        # count the # of clones in each timepoint in this iteration\n",
    "        clones_120 = 0\n",
    "        clones_144 = 0\n",
    "        clones_120_144 = 0\n",
    "\n",
    "        # capture the distribution of clones in each timepoint for this iteration in a dict\n",
    "        temp_clone_sizes = {'120': [], '144': [], '120_144': []}\n",
    "        temp_clone_depths = {'120': [], '144': [], '120_144': []}\n",
    "\n",
    "        for clone in clones:\n",
    "            # check if the clone is a single cell, pull the timepoint from the cell state table if so\n",
    "            if clone.startswith('T'):\n",
    "                cell_time = shuffled_cell_state_table[shuffled_cell_state_table['cellBC'] == clone]['timepoint'].tolist()[0]\n",
    "                \n",
    "                if cell_time == 120:\n",
    "                    clones_120 += 1\n",
    "                    temp_clone_sizes['120'].append(1)\n",
    "                    temp_clone_depths['120'].append(0)\n",
    "                elif cell_time == 144:\n",
    "                    clones_144 += 1\n",
    "                    temp_clone_sizes['144'].append(1)\n",
    "                    temp_clone_depths['144'].append(0)\n",
    "\n",
    "            # if the clone is a node, then pull its timepoint from the node info table\n",
    "            else:\n",
    "                if node_info_itr.loc[clone, 'node_time'] == '120':\n",
    "                    clones_120 += 1\n",
    "                    temp_clone_sizes['120'].append(node_info_itr.loc[clone, 'clone_size'])\n",
    "                    temp_clone_depths['120'].append(node_info_itr.loc[clone, 'max_clone_depth'])\n",
    "                elif node_info_itr.loc[clone, 'node_time'] == '144':\n",
    "                    clones_144 += 1\n",
    "                    temp_clone_sizes['144'].append(node_info_itr.loc[clone, 'clone_size'])\n",
    "                    temp_clone_depths['144'].append(node_info_itr.loc[clone, 'max_clone_depth'])\n",
    "                else:\n",
    "                    clones_120_144 += 1\n",
    "                    temp_clone_sizes['120_144'].append(node_info_itr.loc[clone, 'clone_size'])\n",
    "                    temp_clone_depths['120_144'].append(node_info_itr.loc[clone, 'max_clone_depth'])\n",
    "\n",
    "        # record the # of clones in each timepoint\n",
    "        df_bgClones.loc['120', 'itr{}'.format(itr)] = clones_120\n",
    "        df_bgClones.loc['144', 'itr{}'.format(itr)] = clones_144\n",
    "        df_bgClones.loc['120_144', 'itr{}'.format(itr)] = clones_120_144\n",
    "        \n",
    "        for time in time_types:\n",
    "            df_bgCounts.loc[time, 'itr{}'.format(itr)] = len(node_info_itr[node_info_itr['node_time'] == time]['clone'])\n",
    "            node_depths[time].append(node_info_itr[node_info_itr['node_time'] == time]['norm_dist_to_clone'])\n",
    "            \n",
    "            clone_sizes[time].append(temp_clone_sizes[time])\n",
    "            clone_depths[time].append(temp_clone_depths[time])\n",
    "\n",
    "    if single_cell_clones:\n",
    "        df_bgCounts.to_csv(output_dir + '{}_shuffledBG_Counts.txt'.format(file_name))\n",
    "        df_bgClones.to_csv(output_dir + '{}_shuffledBG_Clones.txt'.format(file_name))\n",
    "        \n",
    "        f = open(output_dir + '{}_clone_sizes.pkl'.format(file_name), \"wb\")\n",
    "        pickle.dump(clone_sizes, f)\n",
    "\n",
    "        f = open(output_dir + '{}_clone_depths.pkl'.format(file_name), \"wb\")\n",
    "        pickle.dump(clone_depths, f)\n",
    "        \n",
    "        f = open(output_dir + '{}_node_depths.pkl'.format(file_name), \"wb\")\n",
    "        pickle.dump(node_depths, f)\n",
    "    else:\n",
    "        df_bgCounts.to_csv(output_dir + '{}_shuffledBG_Counts_without_scClones.txt'.format(file_name))\n",
    "        df_bgClones.to_csv(output_dir + '{}_shuffledBG_Clones_without_scClones.txt'.format(file_name))\n",
    "        \n",
    "        f = open(output_dir + '{}_clone_sizes_without_scClones.pkl'.format(file_name), \"wb\")\n",
    "        pickle.dump(clone_sizes, f)\n",
    "\n",
    "        f = open(output_dir + '{}_clone_depths_without_scClones.pkl'.format(file_name), \"wb\")\n",
    "        pickle.dump(clone_depths, f)\n",
    "        \n",
    "        f = open(output_dir + '{}_node_depths.pkl'.format(file_name), \"wb\")\n",
    "        pickle.dump(node_depths, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753d99c",
   "metadata": {},
   "source": [
    "# Run the time shuffled BG for the hybrid combined trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d44033e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform shuffled background on time assignments\n",
    "for barcode in barcodes:\n",
    "    method = 'hybrid'\n",
    "    time = '120_144'\n",
    "    \n",
    "    treeFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/{}/{}/{}_{}_{}_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, time, method, barcode, time, method)\n",
    "    t = Tree(treeFile, format = 1)\n",
    "    total_leaves = [leaf.name for leaf in t.get_leaves()]\n",
    "\n",
    "    temp_cell_state_table = cell_state_table[cell_state_table['cellBC'].isin(total_leaves)]\n",
    "\n",
    "    # Make empty node file\n",
    "    nodes = []\n",
    "    for node in t.traverse():\n",
    "        if not node.is_leaf() and node.name != 'node0':\n",
    "                nodes.append(node.name)\n",
    "\n",
    "    empty_node_info = pd.DataFrame(index = nodes, columns = ['clone', 'dist_to_clone', 'max_clone_depth', 'clone_size', 'node_time', 'progenitor_type', 'norm_dist_to_clone', 'frac_120'])\n",
    "\n",
    "    # fill node information into the empty node info table\n",
    "    for clone in t.children:\n",
    "        clone_depth = maxDepth(clone)\n",
    "        clone_size = len(clone.get_leaves())\n",
    "\n",
    "        for node in clone.traverse():\n",
    "            if not node.is_leaf():\n",
    "                dist_to_clone = t.get_distance(clone, node)\n",
    "\n",
    "                empty_node_info.loc[node.name, 'clone'] = clone.name\n",
    "                empty_node_info.loc[node.name, 'dist_to_clone'] = dist_to_clone\n",
    "                empty_node_info.loc[node.name, 'max_clone_depth'] = clone_depth\n",
    "                empty_node_info.loc[node.name, 'clone_size'] = clone_size\n",
    "                empty_node_info.loc[node.name, 'norm_dist_to_clone'] = dist_to_clone / clone_depth\n",
    "\n",
    "    actual_node_info = empty_node_info.copy()\n",
    "\n",
    "    for node in t.traverse():\n",
    "        if not node.is_leaf() and node.name != 'node0':\n",
    "            leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "            actual_node_info.loc[node.name, 'progenitor_type'] = getProgenitorType(leaves, temp_cell_state_table)\n",
    "            actual_node_info.loc[node.name, 'node_time'] = getTimeType(leaves, temp_cell_state_table)\n",
    "\n",
    "    for clone in t.children:\n",
    "        if not clone.is_leaf():\n",
    "            actual_node_info.loc[clone.name, 'progenitor_type'] = 'Clone'\n",
    "\n",
    "    actual_node_info.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_{}_{}_actual_node_info.txt'.format(barcode, barcode, time, method), sep = '\\t')\n",
    "\n",
    "    # Make a dictionary that stores the subnodes (not including leaves) for each node in the tree\n",
    "    node_subnode_dict = {}\n",
    "    # Make a dictionary that stores the leaves for each node in the tree\n",
    "    node_leaf_dict = {}\n",
    "\n",
    "    # Iter through all the nodes in t and populate two dictionaries for non-leaf nodes\n",
    "    for node in t.traverse():\n",
    "        if not node.is_leaf():\n",
    "            node_leaf_dict[node.name] = [leaf.name for leaf in node.get_leaves()]\n",
    "\n",
    "            children = []\n",
    "\n",
    "            for subnode in node.traverse():\n",
    "                if not subnode.is_leaf() and subnode != node:\n",
    "                    children.append(subnode.name)\n",
    "\n",
    "            node_subnode_dict[node.name] = children\n",
    "\n",
    "    shuffledBG_time(file_name = '{}_{}_{}'.format(barcode, time, method),\n",
    "                    tree = t,\n",
    "                    empty_node_info = empty_node_info,\n",
    "                    cell_state_table = temp_cell_state_table,\n",
    "                    node_leaf_dict = node_leaf_dict,\n",
    "                    dropped_leaf_dict = {},\n",
    "                    output_dir = '/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/'.format(barcode),\n",
    "                    single_cell_clones = True,\n",
    "                    numShuffles = 500) \n",
    "\n",
    "    shuffledBG_time(file_name = '{}_{}_{}'.format(barcode, time, method),\n",
    "                    tree = t,\n",
    "                    empty_node_info = empty_node_info,\n",
    "                    cell_state_table = temp_cell_state_table,\n",
    "                    node_leaf_dict = node_leaf_dict,\n",
    "                    dropped_leaf_dict = {},\n",
    "                    output_dir = '/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/'.format(barcode),\n",
    "                    single_cell_clones = False,\n",
    "                    numShuffles = 500)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf3149",
   "metadata": {},
   "source": [
    "# Plot the shuffled BG for clone and node times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40cbcc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the shuffled BG for nodes of each timepoint\n",
    "fig, ax = plt.subplots(2, 3, figsize = (15, 10))\n",
    "i = 0\n",
    "j = 0\n",
    "for barcode in barcodes:\n",
    "    method = 'hybrid'\n",
    "    time = '120_144'\n",
    "    \n",
    "    df_bgClones = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_{}_shuffledBG_Counts.txt'.format(barcode, barcode, method), index_col = 0)\n",
    "    actual_node_info = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_{}_actual_node_info.txt'.format(barcode, barcode, method), sep = '\\t', index_col = 0)\n",
    "\n",
    "    # Get the actual values from the above node table\n",
    "    nodes_120 = len(actual_node_info[actual_node_info['node_time'] == '120'])\n",
    "    nodes_144 = len(actual_node_info[actual_node_info['node_time'] == '144'])\n",
    "    nodes_120_144 = len(actual_node_info[actual_node_info['node_time'] == '120_144'])\n",
    "\n",
    "    temp_ax = ax[i, j]\n",
    "    if j >= 2:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "    sns.violinplot(data = df_bgClones.T, scale = 'count', ax = temp_ax)\n",
    "    sns.swarmplot(x = df_bgClones.index, y = [nodes_120, nodes_144, nodes_120_144], color = 'Blue', ax = temp_ax)\n",
    "    temp_ax.set_ylabel('Node Counts')\n",
    "    temp_ax.set_title('{}'.format(barcode))\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/plots/node_timepoints.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5d637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the shuffled BG using shared clone counts not including single cell clones\n",
    "fig, ax = plt.subplots(2, 3, figsize = (15, 10))\n",
    "i = 0\n",
    "j = 0\n",
    "for barcode in barcodes:\n",
    "    method = 'hybrid'\n",
    "    \n",
    "    df_bgClones = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_{}_shuffledBG_Clones_without_scClones.txt'.format(barcode, barcode, method), index_col = 0)\n",
    "    actual_node_info = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_{}_actual_node_info.txt'.format(barcode, barcode, method), sep = '\\t', index_col = 0)\n",
    "\n",
    "\n",
    "    # Get the actual values from the above node table\n",
    "    actual_values = []\n",
    "    count_120 = len(actual_node_info[(actual_node_info['dist_to_clone'] == 0) & (actual_node_info['node_time'] == '120')])\n",
    "    count_144 = len(actual_node_info[(actual_node_info['dist_to_clone'] == 0) & (actual_node_info['node_time'] == '144')])\n",
    "    count_120_144 = len(actual_node_info[(actual_node_info['dist_to_clone'] == 0) & (actual_node_info['node_time'] == '120_144')])\n",
    "\n",
    "    temp_ax = ax[i, j]\n",
    "    if j >= 2:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "    sns.violinplot(data = df_bgClones.T, scale = 'count', ax = temp_ax)\n",
    "    sns.swarmplot(x = df_bgClones.index, y = [count_120, count_144, count_120_144], color = 'Blue', ax = temp_ax)\n",
    "    temp_ax.set_ylabel('Count')\n",
    "    temp_ax.set_title('{} - Without scClones'.format(barcode, method))\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/plots/clone_timepoints.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b316a0b",
   "metadata": {},
   "source": [
    "# Plot the size and max depths of clones of each timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fef6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pdf with all the clone depth distributions\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/plots/clone_depths.pdf')\n",
    "\n",
    "for barcode in barcodes:\n",
    "    actual_node_info = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_hybrid_actual_node_info.txt'.format(barcode, barcode), sep = '\\t', index_col = 0)\n",
    "    with open('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_hybrid_clone_sizes_without_scClones.pkl'.format(barcode, barcode), 'rb') as f:\n",
    "        clone_sizes = pickle.load(f)\n",
    "\n",
    "    # Start a figure for the cdf plots for each progneitor type in the untrimmed not full combination dataset\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "    count = 0\n",
    "    for size in clone_sizes.keys():\n",
    "        temp_ax = ax[count]\n",
    "        count += 1\n",
    "\n",
    "        for i in clone_sizes[size]:\n",
    "            if len(i) > 0:\n",
    "                sns.ecdfplot(i, ax=temp_ax, color = 'lightblue', alpha = 0.1)\n",
    "                temp_ax.set_title(size)\n",
    "    # Plot the actual data\n",
    "    clones = actual_node_info['clone'].unique()\n",
    "\n",
    "    count = 0\n",
    "    for time in clone_sizes.keys():\n",
    "        temp_ax = ax[count]\n",
    "        count += 1\n",
    "\n",
    "        temp_clone_sizes = []\n",
    "        for clone in clones:\n",
    "            if actual_node_info.loc[clone, 'node_time'] == time:\n",
    "                temp_clone_sizes.append(actual_node_info.loc[clone, 'clone_size'])\n",
    "        sns.ecdfplot(temp_clone_sizes, ax = temp_ax, color = 'Black')\n",
    "        temp_ax.set_title('{} - {} - Without scClones'.format(barcode, time))\n",
    "        temp_ax.set_xlabel('Clone Size (Leaves)')\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69eb059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pdf with all the clone depth distributions\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/plots/clone_depths.pdf')\n",
    "\n",
    "for barcode in barcodes:\n",
    "    actual_node_info = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_hybrid_actual_node_info.txt'.format(barcode, barcode), sep = '\\t', index_col = 0)\n",
    "    with open('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_hybrid_clone_sizes_without_scClones.pkl'.format(barcode, barcode), 'rb') as f:\n",
    "        clone_sizes = pickle.load(f)\n",
    "\n",
    "    # Start a figure for the cdf plots for each progneitor type in the untrimmed not full combination dataset\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "    count = 0\n",
    "    for size in clone_sizes.keys():\n",
    "        temp_ax = ax[count]\n",
    "        count += 1\n",
    "\n",
    "        for i in clone_sizes[size]:\n",
    "            if len(i) > 0:\n",
    "                sns.ecdfplot(i, ax=temp_ax, color = 'lightblue', alpha = 0.1)\n",
    "                temp_ax.set_title(size)\n",
    "    # Plot the actual data\n",
    "    clones = actual_node_info['clone'].unique()\n",
    "\n",
    "    count = 0\n",
    "    for time in clone_sizes.keys():\n",
    "        temp_ax = ax[count]\n",
    "        count += 1\n",
    "\n",
    "        temp_clone_sizes = []\n",
    "        for clone in clones:\n",
    "            if actual_node_info.loc[clone, 'node_time'] == time:\n",
    "                temp_clone_sizes.append(actual_node_info.loc[clone, 'max_clone_depth'])\n",
    "        sns.ecdfplot(temp_clone_sizes, ax = temp_ax, color = 'Black')\n",
    "        temp_ax.set_title('{}_{}_Depth without scClones'.format(barcode, time))\n",
    "        #temp_ax.set_xlim(0, 700)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29976d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pdf with all the node depth distributions\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/plots/node_depths.pdf')\n",
    "\n",
    "for barcode in barcodes:\n",
    "    actual_node_info = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_hybrid_actual_node_info.txt'.format(barcode, barcode), sep = '\\t', index_col = 0)\n",
    "    with open('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/{}/{}_120_144_hybrid_node_depths.pkl'.format(barcode, barcode), 'rb') as f:\n",
    "        node_depths = pickle.load(f)\n",
    "\n",
    "    # Start a figure for the cdf plots for each progneitor type in the untrimmed not full combination dataset\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "    count = 0\n",
    "    for time in node_depths.keys():\n",
    "        temp_ax = ax[count]\n",
    "        count += 1\n",
    "\n",
    "        for i in node_depths[time]:\n",
    "            if len(i) > 0:\n",
    "                sns.ecdfplot(i, ax=temp_ax, color = 'lightblue', alpha = 0.1)\n",
    "                temp_ax.set_title(time)\n",
    "    # Plot the actual data\n",
    "\n",
    "    count = 0\n",
    "    for time in node_depths.keys():\n",
    "        temp_ax = ax[count]\n",
    "        count += 1\n",
    "\n",
    "        temp_node_depths = actual_node_info[actual_node_info['node_time'] == time]['norm_dist_to_clone']\n",
    "        sns.ecdfplot(temp_node_depths, ax = temp_ax, color = 'Black')\n",
    "        temp_ax.set_title('{}_{}_Depth'.format(barcode, time))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cc647",
   "metadata": {},
   "source": [
    "# Run the same shuffled BG on clone and node timepoints for the subsampled trees\n",
    "- The subsampled trees are located in /Genomics/chanlab/blaw/TLS/data/explant/subsampling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48d556a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform shuffled background on time assignments\n",
    "for barcode in barcodes:\n",
    "    method = 'hybrid'\n",
    "    time = '120_144'\n",
    "    \n",
    "    treeFile = '/Genomics/chanlab/blaw/TLS/data/explant/subsampling/{}/{}_subsampling_hybrid_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, barcode)\n",
    "    t = Tree(treeFile, format = 1)\n",
    "    total_leaves = [leaf.name for leaf in t.get_leaves()]\n",
    "\n",
    "    temp_cell_state_table = cell_state_table[cell_state_table['cellBC'].isin(total_leaves)]\n",
    "\n",
    "    # Make empty node file\n",
    "    nodes = []\n",
    "    for node in t.traverse():\n",
    "        if not node.is_leaf() and node.name != 'node0':\n",
    "                nodes.append(node.name)\n",
    "\n",
    "    empty_node_info = pd.DataFrame(index = nodes, columns = ['clone', 'dist_to_clone', 'max_clone_depth', 'clone_size', 'node_time', 'progenitor_type', 'norm_dist_to_clone', 'frac_120'])\n",
    "\n",
    "    # fill node information into the empty node info table\n",
    "    for clone in t.children:\n",
    "        clone_depth = maxDepth(clone)\n",
    "        clone_size = len(clone.get_leaves())\n",
    "\n",
    "        for node in clone.traverse():\n",
    "            if not node.is_leaf():\n",
    "                dist_to_clone = t.get_distance(clone, node)\n",
    "\n",
    "                empty_node_info.loc[node.name, 'clone'] = clone.name\n",
    "                empty_node_info.loc[node.name, 'dist_to_clone'] = dist_to_clone\n",
    "                empty_node_info.loc[node.name, 'max_clone_depth'] = clone_depth\n",
    "                empty_node_info.loc[node.name, 'clone_size'] = clone_size\n",
    "                empty_node_info.loc[node.name, 'norm_dist_to_clone'] = dist_to_clone / clone_depth\n",
    "\n",
    "    actual_node_info = empty_node_info.copy()\n",
    "\n",
    "    for node in t.traverse():\n",
    "        if not node.is_leaf() and node.name != 'node0':\n",
    "            leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "            actual_node_info.loc[node.name, 'progenitor_type'] = getProgenitorType(leaves, temp_cell_state_table)\n",
    "            actual_node_info.loc[node.name, 'node_time'] = getTimeType(leaves, temp_cell_state_table)\n",
    "\n",
    "    for clone in t.children:\n",
    "        if not clone.is_leaf():\n",
    "            actual_node_info.loc[clone.name, 'progenitor_type'] = 'Clone'\n",
    "\n",
    "    actual_node_info.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/subsampled/{}/{}_subsampled_actual_node_info.txt'.format(barcode, barcode), sep = '\\t')\n",
    "\n",
    "    # Make a dictionary that stores the subnodes (not including leaves) for each node in the tree\n",
    "    node_subnode_dict = {}\n",
    "    # Make a dictionary that stores the leaves for each node in the tree\n",
    "    node_leaf_dict = {}\n",
    "\n",
    "    # Iter through all the nodes in t and populate two dictionaries for non-leaf nodes\n",
    "    for node in t.traverse():\n",
    "        if not node.is_leaf():\n",
    "            node_leaf_dict[node.name] = [leaf.name for leaf in node.get_leaves()]\n",
    "\n",
    "            children = []\n",
    "\n",
    "            for subnode in node.traverse():\n",
    "                if not subnode.is_leaf() and subnode != node:\n",
    "                    children.append(subnode.name)\n",
    "\n",
    "            node_subnode_dict[node.name] = children\n",
    "\n",
    "    shuffledBG_time(file_name = '{}_subsampled'.format(barcode),\n",
    "                    tree = t,\n",
    "                    empty_node_info = empty_node_info,\n",
    "                    cell_state_table = temp_cell_state_table,\n",
    "                    node_leaf_dict = node_leaf_dict,\n",
    "                    dropped_leaf_dict = {},\n",
    "                    output_dir = '/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/subsampled/{}/'.format(barcode),\n",
    "                    single_cell_clones = True,\n",
    "                    numShuffles = 500) \n",
    "\n",
    "    shuffledBG_time(file_name = '{}_subsampled'.format(barcode),\n",
    "                    tree = t,\n",
    "                    empty_node_info = empty_node_info,\n",
    "                    cell_state_table = temp_cell_state_table,\n",
    "                    node_leaf_dict = node_leaf_dict,\n",
    "                    dropped_leaf_dict = {},\n",
    "                    output_dir = '/Genomics/chanlab/blaw/TLS/data/explant/shuffledBG/subsampled/{}/'.format(barcode),\n",
    "                    single_cell_clones = False,\n",
    "                    numShuffles = 500)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

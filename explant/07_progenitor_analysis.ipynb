{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab10633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from ete3 import Tree\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3322d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dict with color codes for the cell states\n",
    "clusterColorsFile = \"/Genomics/chanlab/mchan/Adriano/TLS/TLS_TLSCL/20211102_clusterColorsTLSCL.p\"\n",
    "with open(clusterColorsFile,'rb') as fp:\n",
    "    colorDict = pickle.load(fp)\n",
    "    \n",
    "# create a dict with color codes for progenitor states\n",
    "progenitor_colorDict = {'Extended Progenitor':'Black', 'Pluripotent Progenitor':'Orange', 'Bipotent Progenitor':'MediumBlue',\n",
    "                        'Neural Progenitor':'DarkGreen', 'Somitic Progenitor':'Purple', 'PGCLC Progenitor': 'Red',\n",
    "                        'Endoderm Progenitor':'Gold', 'Dropped': 'Gray'}    \n",
    "\n",
    "# Load the cell state table\n",
    "total_cell_state_table = pd.read_csv('/Genomics/chanlab/blaw/TLS/metadata/TLS_Explant_Total_cellBC_cellState.tst', sep = '\\t')\n",
    "\n",
    "# Helpful lists\n",
    "barcodes = ['Bar1', 'Bar2', 'Bar3', 'Bar4', 'Bar5', 'Bar6']\n",
    "TLS_barcodes = ['Bar1', 'Bar2', 'Bar3']\n",
    "TLSCL_barcodes = ['Bar4', 'Bar5', 'Bar6']\n",
    "progenitor_list = ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', 'PGCLC Progenitor', 'Endoderm Progenitor', 'Dropped']\n",
    "colors = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', \n",
    "          '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', \n",
    "          '#ffffff', '#000000']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8674e1",
   "metadata": {},
   "source": [
    "# Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac6ce202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxDepth(node):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "    returns:\n",
    "        - The max depth of any branch in that node\n",
    "    '''\n",
    "    if node.is_leaf():\n",
    "        return 0\n",
    "    children_depths = []\n",
    "    \n",
    "    for child in node.children:\n",
    "        test = maxDepth(child)\n",
    "        \n",
    "        children_depths.append(test)\n",
    "        \n",
    "    return max(children_depths) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65961e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNMP_Somite_Neural_other(node, cell_state_table):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree\n",
    "        - a table of cell states for each cellBC\n",
    "    return:\n",
    "        - A tuple of the number of NMP, somitic, and neural cells that are leaves of the node\n",
    "    '''\n",
    "    leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "\n",
    "    # Group the Neural and Somite cell states into 1 category and remove PGCLC, Endoderm, Unknown, Epithelial\n",
    "    somitic_count = 0\n",
    "    NMP_count = 0\n",
    "    neural_count = 0\n",
    "    endoderm_count = 0\n",
    "    endothelial_count = 0\n",
    "    pgc_count = 0\n",
    "    unknown_count = 0\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            somitic_count += 1\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            neural_count += 1\n",
    "        elif state in ['NMPs']:\n",
    "            NMP_count += 1\n",
    "        elif state == 'Endothelial':\n",
    "            endothelial_count += 1\n",
    "        elif state == 'Endoderm':\n",
    "            endoderm_count += 1\n",
    "        elif state == 'PCGLC':\n",
    "            pgc_count += 1\n",
    "        elif state == 'Unknown':\n",
    "            unknown_count += 1\n",
    "\n",
    "    return (NMP_count, somitic_count, neural_count, pgc_count, endoderm_count, endothelial_count, unknown_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82b8114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTimepoint(node):\n",
    "    '''\n",
    "    Input:\n",
    "        - a node in an ete tree. Assumes that the leaf names contain the explant timepoint information. 120h timepoints start\n",
    "        with Tracer_Explant_ on the beginning of each leaf. 144h timespoints start with Tracer_Outgrowth_1 or Tracer_Outgrowth_2\n",
    "        at the beginning of each leaf\n",
    "    return:\n",
    "        - A tuple of the number of 120h and 144h cells for the node\n",
    "    '''\n",
    "    leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "\n",
    "    # Group the Neural and Somite cell states into 1 category and remove PGCLC, Endoderm, Unknown, Epithelial\n",
    "    count_120 = 0\n",
    "    count_144 = 0\n",
    "    for cell in leaves:\n",
    "        # use the cell names to identify timepoint\n",
    "        if cell.startswith('Tracer_Explant'):\n",
    "            count_120 += 1\n",
    "        elif cell.startswith('Tracer_Outgrowth'):\n",
    "            count_144 += 1\n",
    "\n",
    "    return (count_120, count_144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d4165f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProgenitorType(node, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a tree node to test\n",
    "        - a table that contains the annotated cell state for each cellBC\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    - Extended progenitors: PGCs, Endoderm, Somitic, Neural\n",
    "    - Pluripotent progenitors: Endoderm, Somitic, Neural\n",
    "    - Bipotent progenitors: Somitic, Neural (both if contains or not NMPs still count)\n",
    "    - Endoderm progenitors: Endoderm only\n",
    "    - PGCLC progenitors: PGCLC only\n",
    "    - Somitic progenitors: somitic only\n",
    "    - Neural progenitors: neural only\n",
    "    \n",
    "    Neural class is made from NeuralTube1 and NeuralTube2\n",
    "    Somite class is pPSM, aPSM, Somite-1, Somite0, Somite, Somite1, SomiteSclero, SomiteDermo\n",
    "    \n",
    "    NMPs are left out of the analysis. +/- an NMP does not change the category that a node gets\n",
    "    \n",
    "    exclude nodes that are Endoderm without both somitic and neural (unless it is alone)\n",
    "    exclude nodes that are PGC without all 3 endoderm, somitic, and neural (unless it is alone)\n",
    "    \n",
    "    Endothelial is allowed (+/-) in extended progenitors and pluripotent progenitors\n",
    "    Endothelial is not allowed (-) in all other progenitors\n",
    "    \n",
    "    Unassigned / Unknown cells are not looked at for this classification (+/-)\n",
    "    \n",
    "    '''\n",
    "    progenitor_types = {'Extended Progenitor': set(['PCGLC', 'Endoderm', 'Somitic', 'Neural']),\n",
    "                        'Pluripotent Progenitor': set(['Endoderm', 'Somitic', 'Neural']),\n",
    "                        'Bipotent Progenitor' : set(['Somitic', 'Neural']),\n",
    "                        'Endoderm Progenitor': set(['Endoderm']),\n",
    "                        'PGCLC Progenitor': set(['PCGLC']),\n",
    "                        'Somitic Progenitor': set(['Somitic']),\n",
    "                        'Neural Progenitor': set(['Neural'])}\n",
    "    \n",
    "    \n",
    "    leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "    \n",
    "    # Group the cell states into neural and somite categories\n",
    "    grouped_states = []\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            grouped_states.append('Somitic')\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            grouped_states.append('Neural')\n",
    "        elif state in ['PCGLC', 'Endoderm', 'Endothelial']:\n",
    "            grouped_states.append(state)\n",
    "    \n",
    "    state_set = set(grouped_states)\n",
    "    \n",
    "    for progenitor in progenitor_types.keys():\n",
    "        if state_set == progenitor_types[progenitor]:\n",
    "            return progenitor\n",
    "    if state_set == set(['PCGLC', 'Endoderm', 'Somitic', 'Neural', 'Endothelial']):\n",
    "        return 'Extended Progenitor'\n",
    "    if state_set == set(['Endoderm', 'Somitic', 'Neural', 'Endothelial']):\n",
    "        return 'Pluripotent Progenitor'\n",
    "    \n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcf42f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProgenitorType_FC(node, cell_state_table):\n",
    "    '''\n",
    "    input:\n",
    "        - a tree node to test\n",
    "        - a table that contains the annotated cell state for each cellBC\n",
    "    output:\n",
    "        - the type of progenitor that we are classifying it as given these criteria:\n",
    "    \n",
    "    Record the cell states that are connected to a node from the following 6 states:\n",
    "    - PGCLC\n",
    "    - Endoderm\n",
    "    - Endothelial\n",
    "    - NMPs\n",
    "    - Somitic\n",
    "    - Neural\n",
    "    \n",
    "    Neural class is made from NeuralTube1 and NeuralTube2\n",
    "    Somite class is pPSM, aPSM, Somite-1, Somite0, Somite, Somite1, SomiteSclero, SomiteDermo\n",
    "    \n",
    "    Unassigned / Unknown cells are not looked at for this classification (+/-)\n",
    "    \n",
    "    '''\n",
    "    leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "    \n",
    "    states = ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs', 'Somitic', 'Neural']\n",
    "    total_combinations = []\n",
    "    for i in range(5):\n",
    "        for j in itertools.combinations(states, i+2):\n",
    "            total_combinations.append(j)\n",
    "\n",
    "    progenitor_type_dict = {'PCGLC': set(['PCGLC']),\n",
    "                       'Endoderm': set(['Endoderm']),\n",
    "                       'Endothelial': set(['Endothelial']),\n",
    "                       'NMPs': set(['NMPs']),\n",
    "                       'Somitic': set(['Somitic']),\n",
    "                       'Neural': set(['Neural'])}\n",
    "    for i in total_combinations:\n",
    "        label = '_'.join(i)\n",
    "        progenitor_type_dict[label] = set(i)\n",
    "    \n",
    "    # make a list of the cell states in a given node\n",
    "    cell_types = cell_state_table[cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "    \n",
    "    # Group the cell states into neural and somite categories\n",
    "    grouped_states = []\n",
    "    for state in cell_types:\n",
    "        if state in ['pPSM', 'aPSM', 'Somite', 'Somite0', 'Somite1', 'Somite-1', 'SomiteSclero', 'SomiteDermo']:\n",
    "            grouped_states.append('Somitic')\n",
    "        elif state in ['NeuralTube1', 'NeuralTube2']:\n",
    "            grouped_states.append('Neural')\n",
    "        elif state in ['PCGLC', 'Endoderm', 'Endothelial', 'NMPs']:\n",
    "            grouped_states.append(state)\n",
    "    \n",
    "    state_set = set(grouped_states)\n",
    "    \n",
    "    for progenitor in progenitor_type_dict.keys():\n",
    "        if state_set == progenitor_type_dict[progenitor]:\n",
    "            return progenitor\n",
    "    \n",
    "    # Return dropped if a node is not in the progenitor type dict\n",
    "    return 'Dropped'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a7a65",
   "metadata": {},
   "source": [
    "# Create a node table across all experiments\n",
    "\n",
    "I will be doing the progenitor analysis using only hybrid trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc8ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'hybrid'\n",
    "node_columns = ['barcode', 'TLS', 'method', 'node_name', 'node_size', 'clone_name', 'clone_size', 'clone_time',\n",
    "                'max_clone_depth', 'dist_to_root', 'norm_dist_to_clone', 'frac_NMP', 'frac_somitic', 'frac_neural',\n",
    "                'frac_PGC', 'frac_endoderm', 'frac_endothelial', 'frac_unknown', 'frac_120', 'frac_144',\n",
    "                'progenitor_type', 'progenitor_type_FC', 'node_time']\n",
    "node_info = pd.DataFrame(columns = node_columns)\n",
    "\n",
    "for barcode in barcodes:\n",
    "    # Load tree\n",
    "    treeFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/120_144/hybrid/{}_120_144_hybrid_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, barcode)\n",
    "    t = Tree(treeFile, format = 1)\n",
    "\n",
    "    # Add all nodes in the tree to the node_info dataframe\n",
    "    node_names = []\n",
    "    for node in t.traverse():\n",
    "        if node.name != 'node0' and not node.is_leaf():\n",
    "            node_names.append('{}_{}'.format(barcode, node.name))\n",
    "\n",
    "    temp_node_info = pd.DataFrame(index = node_names, columns = node_columns)\n",
    "    node_info = pd.concat((node_info, temp_node_info))\n",
    "\n",
    "    if barcode in TLS_barcodes:\n",
    "        TLS = 'TLS'\n",
    "    elif barcode in TLSCL_barcodes:\n",
    "        TLS = 'TLSCL'\n",
    "\n",
    "    # fill in node information, don't keep the root nodes since we know that these structures started from multiple cells\n",
    "    for clone in t.children:\n",
    "        clone_max_depth = maxDepth(clone)\n",
    "        clone_120, clone_144 = countTimepoint(clone)\n",
    "        if clone_120 != 0 and clone_144 != 0:\n",
    "            clone_time = '120_144'\n",
    "        elif clone_120 != 0:\n",
    "            clone_time = '120'\n",
    "        elif clone_144 != 0:\n",
    "            clone_time = '144'\n",
    "\n",
    "        for node in clone.traverse():\n",
    "            if not node.is_leaf():\n",
    "                ID = '{}_{}'.format(barcode, node.name)\n",
    "                leaves = [leaf.name for leaf in node.get_leaves()]\n",
    "                cell_types = total_cell_state_table[total_cell_state_table['cellBC'].isin(leaves)]['cell_state'].to_list()\n",
    "\n",
    "                NMP_count, somitic_count, neural_count, pgc_count, endoderm_count, endothelial_count, unknown_count = countNMP_Somite_Neural_other(node, total_cell_state_table)\n",
    "                count_120, count_144 = countTimepoint(node)\n",
    "\n",
    "                total_time = count_120 + count_144\n",
    "                total = somitic_count + NMP_count + neural_count + pgc_count + endoderm_count + endothelial_count + unknown_count\n",
    "\n",
    "                NMP_frac = NMP_count / total\n",
    "                somitic_frac = somitic_count / total\n",
    "                neural_frac = neural_count / total\n",
    "                pgc_frac = pgc_count / total\n",
    "                endoderm_frac = endoderm_count / total\n",
    "                endothelial_frac = endothelial_count / total\n",
    "                unknown_frac = unknown_count / total\n",
    "\n",
    "                frac_120 = count_120 / total_time\n",
    "                frac_144 = count_144 / total_time\n",
    "\n",
    "                progenitor = getProgenitorType(node, total_cell_state_table)\n",
    "                progenitor_FC = getProgenitorType_FC(node, total_cell_state_table)\n",
    "                if frac_120 != 0 and frac_144 != 0:\n",
    "                    timepoint = '120_144'\n",
    "                elif frac_120 != 0:\n",
    "                    timepoint = '120'\n",
    "                elif frac_144 != 0:\n",
    "                    timepoint = '144'\n",
    "\n",
    "                # Record node information to the large table\n",
    "                node_info.loc[ID, 'barcode'] = barcode\n",
    "                node_info.loc[ID, 'TLS'] = TLS\n",
    "                node_info.loc[ID, 'method'] = method\n",
    "                node_info.loc[ID, 'node_name'] = '{}_{}'.format(barcode, node.name)\n",
    "                node_info.loc[ID, 'node_size'] = len(node.get_leaves())\n",
    "                node_info.loc[ID, 'clone_name'] = '{}_{}'.format(barcode, clone.name)\n",
    "                node_info.loc[ID, 'clone_size'] = len(clone.get_leaves())\n",
    "                node_info.loc[ID, 'clone_time'] = clone_time\n",
    "                node_info.loc[ID, 'max_clone_depth'] = clone_max_depth\n",
    "                node_info.loc[ID, 'dist_to_root'] = t.get_distance(t, node)\n",
    "                node_info.loc[ID, 'norm_dist_to_clone'] = t.get_distance(clone, node) / clone_max_depth\n",
    "                node_info.loc[ID, 'frac_NMP'] = NMP_frac\n",
    "                node_info.loc[ID, 'frac_somitic'] = somitic_frac\n",
    "                node_info.loc[ID, 'frac_neural'] = neural_frac\n",
    "                node_info.loc[ID, 'frac_PGC'] = pgc_frac\n",
    "                node_info.loc[ID, 'frac_endoderm'] = endoderm_frac\n",
    "                node_info.loc[ID, 'frac_endothelial'] = endothelial_frac\n",
    "                node_info.loc[ID, 'frac_unknown'] = unknown_frac\n",
    "                node_info.loc[ID, 'frac_120'] = frac_120\n",
    "                node_info.loc[ID, 'frac_144'] = frac_144\n",
    "\n",
    "                node_info.loc[ID, 'progenitor_type'] = progenitor\n",
    "                node_info.loc[ID, 'progenitor_type_FC'] = progenitor_FC\n",
    "                node_info.loc[ID, 'node_time'] = timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a782b",
   "metadata": {},
   "source": [
    "# add a column to record if a node would be trimmed via the time or progenitor state\n",
    "progenitor trimming\n",
    "- a node would be trimmed if the node is unipotent and it's parent is unipotent\n",
    "\n",
    "time trimming:\n",
    "- a node would be trimmed if the node is a singular time (all extant cells are 120 or 144) and its parent node is as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd643852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary where the key is each node, and the values are the parent node\n",
    "parent_dict = {}\n",
    "# a dictionary where the key is the last node in a branch, and the values are a list of the nodes in the branch\n",
    "branches = {}\n",
    "\n",
    "for barcode in barcodes:\n",
    "    treeFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/120_144/hybrid/{}_120_144_hybrid_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, barcode)\n",
    "    t = Tree(treeFile, format = 1)\n",
    "    \n",
    "    for node in t.traverse():\n",
    "        if not node.is_root() and not node.is_leaf():\n",
    "            parent_dict['{}_{}'.format(barcode, node.name)] = '{}_{}'.format(barcode, node.up.name)\n",
    "            \n",
    "            # if the node has a child that is a leaf, then it is the end of a branch\n",
    "            # this will mean that some branches are subsets of other branches\n",
    "            for child in node.children:\n",
    "                if child.is_leaf():\n",
    "                    branches['{}_{}'.format(barcode, node.name)] = []\n",
    "                    \n",
    "# fill in the branch information for every key\n",
    "for end in branches.keys():\n",
    "    # the key is the last step in the branch\n",
    "    bar = end.split('_')[0]\n",
    "    current = end\n",
    "    \n",
    "    # don't record the root node, branches start at clones\n",
    "    while current != '{}_node0'.format(bar):\n",
    "        # identify the parent of the current node\n",
    "        top = parent_dict[current]\n",
    "        # add the parent to the front of the branch\n",
    "        branches[end].insert(0, current)\n",
    "        # set the current node to the parent\n",
    "        current = top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b41440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to record the trimming information\n",
    "node_info['time_trim'] = 'No'\n",
    "node_info['progenitor_trim'] = 'No'\n",
    "\n",
    "# for every node that is not a clone, classify it based off its parent node\n",
    "# clones will never be trimmed because they are the first node in the branch\n",
    "for node in node_info[node_info['dist_to_root'] > 1].index:\n",
    "    node_name = node_info.loc[node, 'node_name']\n",
    "    parent_name = parent_dict[node_name]\n",
    "    \n",
    "    # collect progenitor type and time of the parent node\n",
    "    parent_progenitor = node_info[node_info['node_name'] == parent_name]['progenitor_type'].to_list()[0]\n",
    "    parent_time = node_info[node_info['node_name'] == parent_name]['node_time'].to_list()[0]\n",
    "\n",
    "    # If the parent node is unipotent or a singular time, then the child node will also be that type\n",
    "    if parent_progenitor in ['Somitic Progenitor', 'Neural Progenitor', 'Endoderm Progenitor', 'PGCLC Progenitor']:\n",
    "        node_info.loc[node, 'progenitor_trim'] = 'Yes'\n",
    "    if parent_time in ['120', '144']:\n",
    "        node_info.loc[node, 'time_trim'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db06f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_explant_hybrid_node_info.txt', sep = '\\t', index = False)\n",
    "\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_explant_hybrid_parent_dict.pickle'.format(method), 'wb') as handle:\n",
    "    pickle.dump(parent_dict, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "with open('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_explant_hybrid_branches_dict.pickle'.format(method), 'wb') as handle:\n",
    "    pickle.dump(branches, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24403aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load node info table\n",
    "node_info = pd.read_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_explant_hybrid_node_info.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ee21a",
   "metadata": {},
   "source": [
    "# Count how many clones come from each timepoint\n",
    "\n",
    "- For these counts, we will not be counting clones that only have a single cell because our sampling is not enough to capture if they had interspersed potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e183f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_counts_without_scClones = pd.DataFrame(index = barcodes, columns = ['gen_1', 'gen_2', 'interspersed'])\n",
    "\n",
    "# Fill in the # of unique clones per barcode per clone timepoint\n",
    "for barcode in barcodes:\n",
    "    clone_counts_without_scClones.loc[barcode, 'gen_1'] = len(node_info[(node_info['barcode'] == barcode) & (node_info['clone_time'] == '120')]['clone_name'].unique())\n",
    "    clone_counts_without_scClones.loc[barcode, 'gen_2'] = len(node_info[(node_info['barcode'] == barcode) & (node_info['clone_time'] == '144')]['clone_name'].unique())\n",
    "    clone_counts_without_scClones.loc[barcode, 'interspersed'] = len(node_info[(node_info['barcode'] == barcode) & (node_info['clone_time'] == '120_144')]['clone_name'].unique())\n",
    "    \n",
    "clone_counts_without_scClones.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/Explant_clone_counts_without_scClones.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6da23",
   "metadata": {},
   "source": [
    "# Remove nodes that belong to clones from only 1 timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ccc5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info_filtered = node_info[node_info['clone_time'] == '120_144'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f425e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info_filtered.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_explant_hybrid_node_info_shared_clones.txt', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae11cee",
   "metadata": {},
   "source": [
    "# Plotting progenitor dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7cd17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of normalized depth of nodes in each time (only in shared clones)\n",
    "fig, ax = plt.subplots(figsize = (5, 3))\n",
    "\n",
    "temp = node_info_filtered[node_info_filtered['TLS'] == 'TLS'].copy()\n",
    "\n",
    "data = [temp[temp['node_time'] == '120']['norm_dist_to_clone'].tolist(),\n",
    "        temp[temp['node_time'] == '144']['norm_dist_to_clone'].tolist(),\n",
    "        temp[temp['node_time'] == '120_144']['norm_dist_to_clone'].tolist()]\n",
    "\n",
    "sns.violinplot(data = data, ax = ax, scale = 'width', cut = 0)\n",
    "ax.set_xticklabels(['Gen1', 'Gen2', 'Combined'])\n",
    "ax.set_title('TLS Node Depths')\n",
    "ax.set_ylabel('Norm Dist to Clone')\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_node_depths.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea7f861d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make a random distribution from 0 to 1 with 1500 items to scale the violin plots in TLS\n",
    "random_vals = []\n",
    "for i in range(1500):\n",
    "    random_vals.append(np.random.uniform(0, 1))\n",
    "\n",
    "# Make a violin plot of progenitor node depths for nodes in each timepoint\n",
    "temp_node_info = node_info_filtered[(node_info_filtered['TLS'] == 'TLS')].copy()\n",
    "fig, ax = plt.subplots(3, 1, figsize = (15, 15))\n",
    "\n",
    "count = 0\n",
    "for time in ['120_144', '120', '144']: \n",
    "    if time == '120':\n",
    "        time_label = 'Gen 1'\n",
    "    elif time == '144':\n",
    "        time_label = 'Gen 2'\n",
    "    else:\n",
    "        time_label = 'Interspersed'\n",
    "    temp_ax = ax[count]\n",
    "    count += 1\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for progenitor in ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor']:\n",
    "        data.append(temp_node_info[(temp_node_info['progenitor_type'] == progenitor) & (temp_node_info['node_time'] == time)]['norm_dist_to_clone'])\n",
    "\n",
    "    data.append(random_vals)\n",
    "    sns.violinplot(data = data, scale = 'count', ax = temp_ax, cut = 0)\n",
    "    temp_ax.set_ylim(0, 1)\n",
    "    temp_ax.set_xticklabels(['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', '1500_random'])\n",
    "    temp_ax.set_ylabel('Norm Dist')\n",
    "    temp_ax.set_title('{}_{}'.format(time_label, 'TLS'))\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_Progenitor_Types_by_Timepoint.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1239ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vals = []\n",
    "for i in range(750):\n",
    "    random_vals.append(np.random.uniform(0, 1))\n",
    "\n",
    "temp_node_info = node_info_filtered[(node_info_filtered['TLS'] == 'TLSCL')].copy()\n",
    "fig, ax = plt.subplots(3, 1, figsize = (15, 15))\n",
    "\n",
    "count = 0\n",
    "for time in ['120_144', '120', '144']: \n",
    "    if time == '120':\n",
    "        time_label = 'Gen 1'\n",
    "    elif time == '144':\n",
    "        time_label = 'Gen 2'\n",
    "    else:\n",
    "        time_label = 'Interspersed'\n",
    "    temp_ax = ax[count]\n",
    "    count += 1\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for progenitor in ['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor']:\n",
    "        data.append(temp_node_info[(temp_node_info['progenitor_type'] == progenitor) & (temp_node_info['node_time'] == time)]['norm_dist_to_clone'])\n",
    "        \n",
    "    data.append(random_vals)\n",
    "    sns.violinplot(data = data, scale = 'count', ax = temp_ax, cut = 0)\n",
    "    temp_ax.set_ylim(0, 1)\n",
    "    temp_ax.set_xticklabels(['Extended Progenitor', 'Pluripotent Progenitor', 'Bipotent Progenitor', 'Neural Progenitor', 'Somitic Progenitor', '750_Scale'])\n",
    "    temp_ax.set_ylabel('Norm Dist')\n",
    "    temp_ax.set_title('{}_{}'.format(time_label, 'TLSCL'))\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLSCL_Progenitor_Types_by_Timepoint.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c179b1",
   "metadata": {},
   "source": [
    "# Create singular timepoint subtrees\n",
    "I am interested in looking at the subtrees that occur after a interspersed node becomes entirely Gen 1 or Gen 2\n",
    "\n",
    "From these trees, I can investigate how the potential of nodes changes once they restrict to a timepoint\n",
    "\n",
    "This does necessarily mean that this potential occurs at this timepoint, because there is a spatial component to this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0204471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict that stores the subtrees after interspersed. The key is the first node after the interspersed node and value is a list of the nodes under the tree \n",
    "sub_trees = {}\n",
    "# a dict of the max depth of each subtree\n",
    "sub_trees_depths = {}\n",
    "\n",
    "for node_ID in node_info_filtered.index:\n",
    "    node_name = node_info_filtered.loc[node_ID, 'node_name']\n",
    "    parent_name = parent_dict[node_name]\n",
    "    \n",
    "    # remove nodes that have both 120 and 144 cells\n",
    "    if node_info_filtered.loc[node_ID, 'node_time'] != '120_144':\n",
    "        # if the parent node has both 120 and 144 cells, then the node is the start of a subtree\n",
    "        if node_info_filtered[node_info_filtered['node_name'] == parent_name]['node_time'].tolist()[0] == '120_144':\n",
    "            sub_trees[node_name] = []\n",
    "            \n",
    "# remove all nodes that have both 120 and 144 cells\n",
    "node_info_subtrees = node_info_filtered[node_info_filtered['node_time'] != '120_144'].copy()\n",
    "\n",
    "for barcode in barcodes:\n",
    "    treeFile = '/Genomics/chanlab/blaw/TLS/data/explant/lineage/3_lineage_reconstruction/{}/120_144/hybrid/{}_120_144_hybrid_newick_noMutationlessEdges_Labeled.nwk'.format(barcode, barcode)\n",
    "    t = Tree(treeFile, format = 1)\n",
    "    \n",
    "    for node in t.traverse():\n",
    "        name = '{}_{}'.format(barcode, node.name)\n",
    "        \n",
    "        if name in sub_trees.keys():\n",
    "            sub_trees_depths[name] = maxDepth(node)\n",
    "            \n",
    "            for subnode in node.traverse():\n",
    "                if not subnode.is_leaf():\n",
    "                    sub_trees[name].append('{}_{}'.format(barcode, subnode.name))\n",
    "    \n",
    "node_info_subtrees.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/TLS_explant_hybrid_node_info_subtrees.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "720a1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "progenitors_120 = {}\n",
    "progenitors_144 = {}\n",
    "\n",
    "for progenitor in node_info_subtrees['progenitor_type'].unique():\n",
    "    progenitors_120[progenitor] = len(node_info_subtrees[(node_info_subtrees['progenitor_type'] == progenitor) & (node_info_subtrees['node_time'] == '120')])\n",
    "    progenitors_144[progenitor] = len(node_info_subtrees[(node_info_subtrees['progenitor_type'] == progenitor) & (node_info_subtrees['node_time'] == '144')])\n",
    "    \n",
    "rows = []\n",
    "for bar in barcodes:\n",
    "    rows.append(bar + '_120')\n",
    "    rows.append(bar + '_144')\n",
    "subtree_progenitors = pd.DataFrame(index = rows, columns = progenitor_list + ['timepoint'])\n",
    "\n",
    "\n",
    "for i in subtree_progenitors.index:\n",
    "    barcode = i.split('_')[0]\n",
    "    time = i.split('_')[1]\n",
    "    barcode_list = []\n",
    "    for progenitor in progenitor_list:\n",
    "        barcode_list.append(len(node_info_subtrees[(node_info_subtrees['barcode'] == barcode) & (node_info_subtrees['progenitor_type'] == progenitor) & (node_info_subtrees['node_time'] == time)]))\n",
    "        \n",
    "    barcode_list.append(time)\n",
    "    subtree_progenitors.loc[i] = barcode_list\n",
    "    \n",
    "\n",
    "subtree_progenitors_frac = subtree_progenitors.drop(columns = ['timepoint']).copy()\n",
    "subtree_progenitors_frac = subtree_progenitors_frac.div(subtree_progenitors_frac.sum(axis=1), axis=0)\n",
    "subtree_progenitors_frac['timepoint'] = subtree_progenitors['timepoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fabbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record counts per subtree\n",
    "subtrees_df = pd.DataFrame(index = sub_trees.keys(), columns = progenitor_list + ['barcode', 'TLS', 'timepoint', 'size', 'parent'])\n",
    "\n",
    "for subtree in sub_trees.keys():\n",
    "    subtree_info = []\n",
    "    barcode = subtree.split('_')[0]\n",
    "    subnodes = sub_trees[subtree]\n",
    "    \n",
    "    TLS = node_info_subtrees[node_info_subtrees['node_name'].isin(subnodes)]['TLS'].tolist()[0]\n",
    "    Timepoint = node_info_subtrees[node_info_subtrees['node_name'].isin(subnodes)]['node_time'].tolist()[0]\n",
    "    size = len(subnodes)\n",
    "    \n",
    "    for progenitor in progenitor_list:\n",
    "        subtree_info.append(len(node_info_subtrees[(node_info_subtrees['node_name'].isin(subnodes)) & (node_info_subtrees['progenitor_type'] == progenitor)]))\n",
    "        \n",
    "    subtree_info.append(barcode)\n",
    "    subtree_info.append(TLS)\n",
    "    subtree_info.append(Timepoint)\n",
    "    subtree_info.append(size)\n",
    "    subtree_info.append(parent_dict[subtree])\n",
    "    \n",
    "    subtrees_df.loc[subtree] = subtree_info\n",
    "    \n",
    "subtrees_df['barcode'] = [int(i[3:]) for i in subtrees_df['barcode']]\n",
    "\n",
    "for col in progenitor_list:\n",
    "    subtrees_df[col] = pd.to_numeric(subtrees_df[col])\n",
    "    \n",
    "subtrees_frac = subtrees_df.copy()\n",
    "for index in subtrees_frac.index:\n",
    "    subtrees_frac.loc[index, progenitor_list] = subtrees_frac.loc[index, progenitor_list] / subtrees_df.loc[index, progenitor_list].sum()\n",
    "    \n",
    "subtrees_df.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_progenitor_counts.txt', sep = '\\t')\n",
    "subtrees_frac.to_csv('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_progenitor_fracs.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9aa736df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fraction of all subtree nodes per progenitor type\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_progenitor_fractions.pdf')\n",
    "for progenitor in progenitor_list:\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (15, 5))\n",
    "    x = []\n",
    "    y = []\n",
    "    for index in subtree_progenitors_frac.index:\n",
    "        x.append(index)\n",
    "        y.append(subtree_progenitors_frac.loc[index, progenitor])\n",
    "    \n",
    "    plt.bar(x = x, height = y)\n",
    "    plt.title('{} Fraction of Nodes'.format(progenitor))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel('Fraction of Subtree Nodes')\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f77b5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of subtree progenitor fractions\n",
    "pp = PdfPages('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_progenitor_fraction_distributions.pdf')\n",
    "for progenitor in progenitor_list:\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (15, 5))\n",
    "    sns.violinplot(data = subtrees_frac, x = 'barcode', y = progenitor, split = True, hue = 'timepoint', cut = 0, ax = ax, scale = 'width')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pp.savefig()\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e25f3",
   "metadata": {},
   "source": [
    "# Plot TLS vs TLSCL mean fraction of progenitor nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fde5dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "error = []\n",
    "xlabels = ['TLS - Gen1', 'TLS - Gen2', 'TLSCL - Gen1', ' TLSCL - Gen2']\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar1_120', 'Bar2_120', 'Bar3_120']]['Bipotent Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar1_120', 'Bar2_120', 'Bar3_120']]['Bipotent Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar1_144', 'Bar2_144', 'Bar3_144']]['Bipotent Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar1_144', 'Bar2_144', 'Bar3_144']]['Bipotent Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar4_120', 'Bar5_120', 'Bar6_120']]['Bipotent Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar4_120', 'Bar5_120', 'Bar6_120']]['Bipotent Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar4_144', 'Bar5_144', 'Bar6_144']]['Bipotent Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar4_144', 'Bar5_144', 'Bar6_144']]['Bipotent Progenitor'].std())\n",
    "\n",
    "plt.bar(x = xlabels, height = data, yerr = error)\n",
    "plt.ylabel('Fraction Bipotent')\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_bipotent_frac.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbc68652",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "error = []\n",
    "xlabels = ['TLS - Gen1', 'TLS - Gen2', 'TLSCL - Gen1', ' TLSCL - Gen2']\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar1_120', 'Bar2_120', 'Bar3_120']]['Somitic Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar1_120', 'Bar2_120', 'Bar3_120']]['Somitic Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar1_144', 'Bar2_144', 'Bar3_144']]['Somitic Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar1_144', 'Bar2_144', 'Bar3_144']]['Somitic Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar4_120', 'Bar5_120', 'Bar6_120']]['Somitic Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar4_120', 'Bar5_120', 'Bar6_120']]['Somitic Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar4_144', 'Bar5_144', 'Bar6_144']]['Somitic Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar4_144', 'Bar5_144', 'Bar6_144']]['Somitic Progenitor'].std())\n",
    "\n",
    "plt.bar(x = xlabels, height = data, yerr = error)\n",
    "plt.ylabel('Fraction Somitic')\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_somitic_frac.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8cf002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "error = []\n",
    "xlabels = ['TLS - Gen1', 'TLS - Gen2', 'TLSCL - Gen1', ' TLSCL - Gen2']\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar1_120', 'Bar2_120', 'Bar3_120']]['Neural Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar1_120', 'Bar2_120', 'Bar3_120']]['Neural Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar1_144', 'Bar2_144', 'Bar3_144']]['Neural Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar1_144', 'Bar2_144', 'Bar3_144']]['Neural Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar4_120', 'Bar5_120', 'Bar6_120']]['Neural Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar4_120', 'Bar5_120', 'Bar6_120']]['Neural Progenitor'].std())\n",
    "\n",
    "data.append(subtree_progenitors_frac.loc[['Bar4_144', 'Bar5_144', 'Bar6_144']]['Neural Progenitor'].mean())\n",
    "error.append(subtree_progenitors_frac.loc[['Bar4_144', 'Bar5_144', 'Bar6_144']]['Neural Progenitor'].std())\n",
    "\n",
    "plt.bar(x = xlabels, height = data, yerr = error)\n",
    "plt.ylabel('Fraction Neural')\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_neural_frac.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83c5e9",
   "metadata": {},
   "source": [
    "# Plot stacked bar plots of the progenitor nodes in the subtrees\n",
    "- These plots will be for TLS and TLSCL\n",
    "\n",
    "- I will show the weighted average of the 3 replicates\n",
    "\n",
    "- For this I will count all nodes, splitting them into 3 categories (gen1 nodes, gen2 nodes, and interspersed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d164791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted avg fraction of each progenitor in the TLS subtrees\n",
    "TLS_subtree_weighted_fracs = pd.DataFrame(0, index = ['120', '120_144', '144'], columns = progenitor_list)\n",
    "\n",
    "for barcode in TLS_barcodes:\n",
    "    # count the progenitor counts for each progenitor in each timepoint only using the top node from each subtree\n",
    "    temp = subtrees_df[(subtrees_df['barcode'] == int(barcode[-1]))].copy()\n",
    "    \n",
    "    # collect the fractions of progenitor types in gen1 and gen2\n",
    "    for progenitor in progenitor_list:\n",
    "        if temp[temp['timepoint'] == '120'][progenitor_list].sum().sum() == 0:\n",
    "            TLS_subtree_weighted_fracs.loc['120', progenitor] = 0\n",
    "            TLS_subtree_weighted_fracs.loc['144', progenitor] = 0\n",
    "        else:\n",
    "            TLS_subtree_weighted_fracs.loc['120', progenitor] += temp[temp['timepoint'] == '120'][progenitor].sum() / temp[temp['timepoint'] == '120'][progenitor_list].sum().sum()\n",
    "            TLS_subtree_weighted_fracs.loc['144', progenitor] += temp[temp['timepoint'] == '144'][progenitor].sum() / temp[temp['timepoint'] == '144'][progenitor_list].sum().sum()\n",
    "\n",
    "    # add the 120_144 counts for TLS\n",
    "    for progenitor in progenitor_list:\n",
    "        TLS_subtree_weighted_fracs.loc['120_144', progenitor] += len(node_info_filtered[(node_info_filtered['barcode'] == barcode) & (node_info_filtered['node_time'] == '120_144') & node_info_filtered['progenitor_type'].isin([progenitor])]) / len(node_info_filtered[(node_info_filtered['barcode'] == barcode) & (node_info_filtered['node_time'] == '120_144') & node_info_filtered['progenitor_type'].isin(progenitor_list)])\n",
    "\n",
    "TLS_subtree_weighted_fracs = TLS_subtree_weighted_fracs.div(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec295963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted avg fraction of each progenitor in the TLS subtrees\n",
    "TLSCL_subtree_weighted_fracs = pd.DataFrame(0, index = ['120', '120_144', '144'], columns = progenitor_list)\n",
    "\n",
    "for barcode in TLSCL_barcodes:\n",
    "    # count the progenitor counts for each progenitor in each timepoint only using the top node from each subtree\n",
    "    temp = subtrees_df[(subtrees_df['barcode'] == int(barcode[-1]))].copy()\n",
    "    \n",
    "    for progenitor in progenitor_list:\n",
    "        if temp[temp['timepoint'] == '120'][progenitor_list].sum().sum() == 0:\n",
    "            TLSCL_subtree_weighted_fracs.loc['120', progenitor] = 0\n",
    "            TLSCL_subtree_weighted_fracs.loc['144', progenitor] = 0\n",
    "        else:\n",
    "            TLSCL_subtree_weighted_fracs.loc['120', progenitor] += temp[temp['timepoint'] == '120'][progenitor].sum() / temp[temp['timepoint'] == '120'][progenitor_list].sum().sum()\n",
    "            TLSCL_subtree_weighted_fracs.loc['144', progenitor] += temp[temp['timepoint'] == '144'][progenitor].sum() / temp[temp['timepoint'] == '144'][progenitor_list].sum().sum()\n",
    "\n",
    "    # add the 120_144 counts for TLS\n",
    "    for progenitor in progenitor_list:\n",
    "        TLSCL_subtree_weighted_fracs.loc['120_144', progenitor] += len(node_info_filtered[(node_info_filtered['barcode'] == barcode) & (node_info_filtered['node_time'] == '120_144') & node_info_filtered['progenitor_type'].isin([progenitor])]) / len(node_info_filtered[(node_info_filtered['barcode'] == barcode) & (node_info_filtered['node_time'] == '120_144') & node_info_filtered['progenitor_type'].isin(progenitor_list)])\n",
    "\n",
    "TLSCL_subtree_weighted_fracs = TLSCL_subtree_weighted_fracs.div(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83f8af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (15, 6))\n",
    "\n",
    "ax1 = ax[0]\n",
    "TLS_subtree_weighted_fracs.plot.bar(stacked = True, color = progenitor_colorDict, ax = ax1, legend = False)\n",
    "ax1.set_xticklabels(['Gen 1', 'All Interspersed', 'Gen 2'])\n",
    "ax1.set_title('TLS Subtree Weighted Avg Fractions')\n",
    "ax1.set_ylabel('Fraction of Nodes')\n",
    "\n",
    "ax2 = ax[1]\n",
    "TLSCL_subtree_weighted_fracs.plot.bar(stacked = True, color = progenitor_colorDict, ax = ax2)\n",
    "ax2.set_xticklabels(['Gen 1', 'All Interspersed', 'Gen 2'])\n",
    "ax2.set_title('TLSCL Subtree Weighted Avg Fractions')\n",
    "ax2.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax2.set_ylabel('Fraction of Nodes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Genomics/chanlab/blaw/TLS/data/explant/progenitor_analysis/subtree_weighted_progenitor_fractions.pdf', dpi = 300)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
